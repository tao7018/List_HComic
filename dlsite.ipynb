{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "みちきんぐ 21 num\n",
      "========v1\n",
      "2015/12/02,03:20\n",
      "03:20\n",
      "page:1\n",
      "21 .\n",
      "ok\n",
      "3 .. 2 .. 1 ..\n",
      "Press Any Key To Exit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import urllib , requests , sys ,string ,time\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "from time import gmtime, strftime\n",
    "#dlsite\n",
    "#fkey作者來源key.txt\n",
    "#fcomiclist結果key_dlsite.text\n",
    "\n",
    "#輸出格式：\n",
    "#dlsite\n",
    "#!作者\n",
    "#!總筆數\n",
    "#==類別_數量_中文敘述\n",
    "#類別_品名\n",
    "#網址\n",
    "\n",
    "#頁顯示數量\n",
    "pnum = 30\n",
    "mlink = 'http://www.dlsite.com/books/'\n",
    "\n",
    "fkey = open('key.txt', 'r')\n",
    "key = fkey.readline()#key=作者\n",
    "fkey.close()\n",
    "\n",
    "#檢查BOM\n",
    "if '%EF%BB%BF' in urllib.quote(key):\n",
    "    print 'fuck ms'\n",
    "\n",
    "'''網址樣本\n",
    "http://www.dlsite.com/maniax/fsr/=/language/jp/sex_category%5B0%5D/male/keyword/\n",
    "urllib.quote(key)\n",
    "/ana_flg/all/order%5B0%5D/release_d/genre_and_or/or/options_and_or/or/per_page/30/show_type/n/page/\n",
    "1\n",
    "'''\n",
    "link = \"http://www.dlsite.com/maniax/fsr/=/language/jp/sex_category%5B0%5D/male/keyword/\"+urllib.quote(key)+\"/ana_flg/all/order%5B0%5D/release_d/genre_and_or/or/options_and_or/or/per_page/30/show_type/n/page/1\"\n",
    "\n",
    "#head = {'User-agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36'}\n",
    "res = requests.get(link)#, headers = head)\n",
    "\n",
    "res.encoding =  res.apparent_encoding#亂碼處理\n",
    "soup = BeautifulSoup(res.text,\"html.parser\")#超出lxml緩存，改其他存取\n",
    "\n",
    "def next(page = 2):\n",
    "    link = \"http://www.dlsite.com/maniax/fsr/=/language/jp/sex_category%5B0%5D/male/keyword/\"+urllib.quote(key)+\"/ana_flg/all/order%5B0%5D/release_d/genre_and_or/or/options_and_or/or/per_page/30/show_type/n/page/\"+str(page)\n",
    "\n",
    "    res = requests.get(link)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    \n",
    "    only_a_tags = SoupStrainer(id=\"search_result_list\")#縮小處理範圍\n",
    "    soup = BeautifulSoup(res.text,\"html.parser\",  parse_only=only_a_tags)\n",
    "    \n",
    "    return soup\n",
    "\n",
    "#全轉半_含轉小寫\n",
    "def Q2B(ustring):\n",
    "    fs=u'０１２３４５６７８９ＱｑＷｗＥｅＲｒＴｔＹｙＵｕＩｉＯｏＰｐＡａＳｓＤｄＦｆＧｇＨｈＪｊＫｋＬｌＺｚＸｘＣｃＶｖＢｂＮｎＭｍ'\n",
    "    hs=u'0123456789QqWwEeRrTtYyUuIiOoPpAaSsDdFfGgHhJjKkLlZzXxCcVvBbNnMm'\n",
    "    rstr = ''\n",
    "    for tm in ustring:\n",
    "        if fs.find(tm)+1:\n",
    "            tm = hs[fs.find(tm)]\n",
    "        rstr = rstr + tm\n",
    "    ustring = rstr\n",
    "    ustring=ustring.lower()\n",
    "    return ustring\n",
    "#半轉全_含轉小寫\n",
    "def B2Q(ustring):\n",
    "    fs=u'０１２３４５６７８９ＱｑＷｗＥｅＲｒＴｔＹｙＵｕＩｉＯｏＰｐＡａＳｓＤｄＦｆＧｇＨｈＪｊＫｋＬｌＺｚＸｘＣｃＶｖＢｂＮｎＭｍ'\n",
    "    hs=u'0123456789QqWwEeRrTtYyUuIiOoPpAaSsDdFfGgHhJjKkLlZzXxCcVvBbNnMm'\n",
    "    rstr = ''\n",
    "    ustring=ustring.lower()\n",
    "    for tm in ustring:\n",
    "        if hs.find(tm)+1:\n",
    "            tm = fs[hs.find(tm)]\n",
    "        rstr = rstr + tm\n",
    "    ustring = rstr\n",
    "    return ustring\n",
    "\n",
    "#資料儲存\n",
    "def save(sdict , check=0):\n",
    "    #print listdata\n",
    "    for temp in listdata:\n",
    "        if sdict.get(temp):\n",
    "            #fout.write(temp.encode('utf8') +sdict[temp].encode('utf8')  + '\\n')\n",
    "            fout.write(sdict[temp].encode('utf8')  + '\\n')\n",
    "    #return\n",
    "\n",
    "#作品頁面\n",
    "def bfind(blink='http://www.dlsite.com/books/'):\n",
    "    res = requests.get(blink)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    ssoup_1 = SoupStrainer(id=\"work_right\")#資訊欄位\n",
    "    ssoup_2 = SoupStrainer(class_=\"work_article work_story\")#內容欄位\n",
    "    \n",
    "    soup1 = BeautifulSoup(res.text,\"lxml\",  parse_only=ssoup_1)#資訊欄位\n",
    "    soup2=BeautifulSoup(res.text,\"lxml\",  parse_only=ssoup_2)#內容欄位\n",
    "    \n",
    "    nnum1=''#作者出現次數\n",
    "    nnum2=''#作者出現次數\n",
    "    bdate1=''#含作者資料\n",
    "    bdate2=''#含作者資料\n",
    "    check=0\n",
    "    cname=''\n",
    "    \n",
    "    nnum1 = Q2B(soup1.text).encode('utf8').count(key)#作者出現次數\n",
    "    nnum2=Q2B(soup2.text).encode('utf8').count(key)\n",
    "    \n",
    "    #資訊欄位\n",
    "    for tm in soup1.select('tr'):\n",
    "        #日期\n",
    "        if u'予告開始日' in tm.text:\n",
    "            check=1\n",
    "            cdata=tm.td.text\n",
    "        elif u'販売日' in tm.text:\n",
    "            cdata=tm.td.text\n",
    "        #類型\n",
    "        if u'作品形式'in tm.text:\n",
    "            ctype='['+tm.td.text+']'\n",
    "        #作者\n",
    "        ##作者不一定有<a>，棄用的方法。\n",
    "        #tmm=tm.select('a')#.get_text('//')\n",
    "        tmm=tm.td\n",
    "        tm=Q2B(tm.text).replace('\\n','')\n",
    "        if key.decode('utf8') in tm:\n",
    "            ##棄用的方法。\n",
    "            #for tmmm in tmm:\n",
    "                #cname=cname+tmmm.text+u'/'\n",
    "            #print tmm,len(tmm)\n",
    "            cname=Q2B(tmm.text).replace('\\n','')\n",
    "            bdate1=bdate1+tm+'_'\n",
    "    bdate1=bdate1[:-1]\n",
    "    \n",
    "    #內容欄位\n",
    "    x=0\n",
    "    if nnum2 > 0:\n",
    "        tm=Q2B(soup2.text)\n",
    "        while tm.find(key.decode('utf8'))>-1:\n",
    "            #以\\n為界的key資料，疊加\n",
    "            ##\\r處理\n",
    "            bdate2=bdate2+'-'+tm[tm.rfind(u'\\n',0,tm.find(key.decode('utf8'))) : tm.find(u'\\n',tm.find(key.decode('utf8')))].strip(u'\\n').strip(u'\\r')+u'\\n'\n",
    "            tm=tm[tm.find(key.decode('utf8'))+1:]\n",
    "            x=x+1\n",
    "            if x>10:\n",
    "                break\n",
    "    #\\n佔用兩格?\n",
    "    bdate2=bdate2.rstrip('\\n')\n",
    "    #'''\n",
    "    \n",
    "    #類型判斷\n",
    "    if int(nnum1) > 0:\n",
    "        check=5\n",
    "        if u'マンガ' in ctype:\n",
    "            check=2\n",
    "            if u'同人' in ctype:\n",
    "                check=4\n",
    "            elif key.decode('utf8') != cname:\n",
    "                check=3\n",
    "                \n",
    "    elif nnum2>0:\n",
    "        if u'マンガ' in ctype:\n",
    "            check=6\n",
    "        else:\n",
    "            check=7\n",
    "    \n",
    "    '''\n",
    "    1新\n",
    "    2漫單\n",
    "    3漫多\n",
    "    4漫同人\n",
    "    5它\n",
    "    6漫\n",
    "    7它\n",
    "    1>4>3>2\n",
    "    #'''\n",
    "    \n",
    "    #print 'bfind'\n",
    "    #類型_nnum1_bdate1_nnum2_bdate2_check\n",
    "    return ctype,nnum1,bdate1,nnum2,bdate2,check\n",
    "\n",
    "#資料處理\n",
    "def findbook(soup , page = 1):\n",
    "    a =0\n",
    "    check = 0\n",
    "    for work_thumb in soup.select('.work_thumb'):\n",
    "        tr = soup.select('tr')[3*a]#資料欄位，間隔3\n",
    "        sou = BeautifulSoup(str(tr),\"lxml\")\n",
    "        \n",
    "        ctype = sou.select('.work_genre')[0].text\n",
    "        cbook = sou.select('.work_name')[0].text\n",
    "        cdata = sou.select('.sales_date')[0].text\n",
    "        #print ctype,cbook,cdata\n",
    "        \n",
    "        #網址\n",
    "        blink = ''\n",
    "        blink = sou.select('.work_name')[0].select('a')[0].get('href')\n",
    "        \n",
    "        #作品處理\n",
    "        #日期_品名\n",
    "        #類型_nnum1_bdate1_nnum2_bdate2\n",
    "        cfind=bfind(blink)\n",
    "        #print '########catch:',len(cfind)#,cfind[:]\n",
    "        ctype=cfind[0]\n",
    "        cnum1=str(cfind[1]).decode('utf8')\n",
    "        cdate1=cfind[2]\n",
    "        cnum2=str(cfind[3]).decode('utf8')\n",
    "        cdate2=cfind[4]\n",
    "        check=cfind[5]\n",
    "        \n",
    "        #品名\n",
    "        book = cbook.replace('\\n','')\n",
    "        \n",
    "        #類型\n",
    "        dtype=ctype\n",
    "        \n",
    "        #日期處理\n",
    "        #予告開始日 : \t2015年04月24日\n",
    "        #販売日: 2015年08月21日\n",
    "        if u'予告開始日' in cdata:\n",
    "            cdata=cdata[7:].replace(u'年','').replace(u'月','').replace(u'日','')\n",
    "            check=1\n",
    "        else:\n",
    "            cdata=cdata[5:].replace(u'年','').replace(u'月','').replace(u'日','')\n",
    "        \n",
    "        #cdata = cdata.rstrip()\n",
    "        if len(cdata) < 4:#無日期\n",
    "            cdata = u'0000/00/00'#填入日期\n",
    "        data = cdata\n",
    "        while listdata.count(data):#重複日期判斷\n",
    "            data = data[:6] + str(int(data[6:]) + 1).rjust(2,'0')#日期+1_十位數填0\n",
    "        listdata.append(data)\n",
    "        #'''\n",
    "        \n",
    "        '''\n",
    "        1新\n",
    "        2漫單\n",
    "        3漫多\n",
    "        4漫同人\n",
    "        5它\n",
    "        6漫\n",
    "        7它\n",
    "        #'''\n",
    "        \n",
    "        #寫入dict\n",
    "        #參考1參考2，無筆數則不紀錄。\n",
    "        if check == 1:#新\n",
    "            #日期_類型_品名_\n",
    "            #!參考1!連結\n",
    "            book=data+'_'+dtype+'_'+book+'_\\n!'+cnum1+'!'+blink\n",
    "            dict1.setdefault(data,book)\n",
    "        elif check == 2:#漫單\n",
    "            #類型_品名_作者資料1_\n",
    "            book=dtype+'_'+book+'_'+cdate1+'_'\n",
    "            dict2.setdefault(data,book)\n",
    "        elif check == 3:#漫多\n",
    "            #類型_品名_作者資料1_\n",
    "            book=dtype+'_'+book+'_'+cdate1+'_'\n",
    "            dict3.setdefault(data,book)\n",
    "        elif check == 4:#漫同人\n",
    "            #類型_品名_作者資料1_\n",
    "            book=dtype+'_'+book+'_'+cdate1+'_'\n",
    "            dict4.setdefault(data,book)\n",
    "        elif check == 5:#它\n",
    "            #類型_品名_作者資料1_\n",
    "            #!參考1!參考2!連結\n",
    "            book=dtype+'_'+book+'_'+cdate1+'_\\n!'+cnum1+'!'+cnum2+'!'+blink\n",
    "            dict5.setdefault(data,book)\n",
    "        elif check == 6:#漫\n",
    "            #類型_品名_\n",
    "            #作者資料2_\n",
    "            #!參考1!參考2!連結\n",
    "            book=dtype+'_'+book+'_\\n'+cdate2+'_\\n!'+cnum1+'!'+cnum2+'!'+blink\n",
    "            dict6.setdefault(data,book)\n",
    "        elif check==7:#它\n",
    "            #類型_品名_\n",
    "            #作者資料2_\n",
    "            #!參考1!參考2!連結\n",
    "            book=dtype+'_'+book+'_\\n'+cdate2+'_\\n!'+cnum1+'!'+cnum2+'!'+blink\n",
    "            dict7.setdefault(data,book)\n",
    "        #print check,'_',book\n",
    "        #'''\n",
    "        a = a + 1\n",
    "        print '\\r',a,\n",
    "        #sys.exit()################\n",
    "    print '.'\n",
    "    #print '========'\n",
    "    #return\n",
    "\n",
    "########\n",
    "key=key.lower()\n",
    "\n",
    "pn=''\n",
    "if len(soup.select('strong'))>0:\n",
    "    pn = soup.select('strong')[0].text#資料筆數\n",
    "\n",
    "#資料筆數_是否數字\n",
    "if pn.isdigit():\n",
    "    if int(pn) > pnum:\n",
    "        print 'BIG'\n",
    "    \n",
    "    fout = open('output/'+key.decode('utf8') + '_dlsitev1.txt', 'w')#寫入模式開檔\n",
    "    fout.write('dlsite\\n')#getchu\n",
    "    print key.decode('utf8') , pn , 'num\\n========v1'\n",
    "    time.sleep(1)\n",
    "    #fout.write('!' + key + '\\n!總筆數' + pn.encode('utf8') + '\\n')\n",
    "    fout.write('!' + key + '\\n!總筆數' + pn.encode('utf8') +'_'+ strftime(\"%Y/%m/%d,%H:%M\")+'->')\n",
    "    \n",
    "    p = 0#頁\n",
    "    #建空輸出用字典與陣列\n",
    "    dict1={}#新\n",
    "    dict2={}#漫單\n",
    "    dict3={}#漫多\n",
    "    dict4={}#漫同人\n",
    "    dict5={}#它\n",
    "    dict7={}#漫\n",
    "    dict6={}#它\n",
    "    listdata = []\n",
    "    check=0\n",
    "    \n",
    "    #資料處理\n",
    "    while (int(pn) - p * pnum) > 0:\n",
    "        p = p + 1\n",
    "        print 'page:' + str(p)\n",
    "        soup = next(p)#頁\n",
    "        \n",
    "        findbook(soup)#資料處理\n",
    "        time.sleep(1)\n",
    "    \n",
    "    #日期排序\n",
    "    listdata.sort()\n",
    "    \n",
    "    fout.write(strftime(\"%H:%M\")+'\\n')\n",
    "    temp = ''\n",
    "    #dict1_新輸出\n",
    "    fout.write('==new_' + str(len(dict1)) +'_新\\n')\n",
    "    save(dict1)\n",
    "    #dict2_漫單輸出\n",
    "    fout.write('==book_' + str(len(dict2)) +'_漫單\\n')\n",
    "    save(dict2)\n",
    "    #dict3_漫多輸出\n",
    "    fout.write('==numbook_' + str(len(dict3)) +'_漫多\\n')\n",
    "    save(dict3)\n",
    "    #dict4_漫同人輸出\n",
    "    fout.write('==dbook_' + str(len(dict4)) +'_漫同人\\n')\n",
    "    save(dict4)\n",
    "    #dict5_它輸出\n",
    "    fout.write('==other_' + str(len(dict5)) +'_它\\n')\n",
    "    save(dict5)\n",
    "    #dict6_漫輸出\n",
    "    fout.write('==obook_' + str(len(dict6)) +'_漫\\n')\n",
    "    save(dict6)\n",
    "    #dict7_它輸出\n",
    "    fout.write('==oother_' + str(len(dict7)) +'_它\\n')\n",
    "    save(dict7)\n",
    "    \n",
    "    fout.close()\n",
    "    print 'ok'\n",
    "elif pn:\n",
    "    print 'No Date'\n",
    "\n",
    "#結束讀秒\n",
    "x=3\n",
    "while x!=0:\n",
    "    print x,'..',\n",
    "    x=x-1\n",
    "    time.sleep(1)\n",
    "raw_input(\"\\nPress Any Key To Exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'int'> <type 'int'>\n",
      "########catch: 6\n",
      "のお店の名前は「駄菓子屋ひより」。\r",
      "-置_\n",
      "134\n",
      "<type 'unicode'> 134\n",
      "<type 'str'> 384\n",
      "-そのお店の名前は「駄菓子屋ひより」。\r",
      "-置いているのは名前の通り、駄菓子の数々。\r",
      "-特別珍しくもない、年季の入った駄菓子屋さんです。\r",
      "-魔法使いになりたい一心で、駄菓子屋に住み込み修行をはじめる。-両親の仕事の都合上、親戚の珠江を頼って駄菓子屋ひよりへやってきた。\r\n",
      "### \n",
      "そのお店の名前は「駄菓子屋ひより」。\r\n",
      "置いているのは名前の通り、駄菓子の数々。\r\n",
      "特別珍しくもない、年季の入った駄菓子屋さんです。\r\n",
      "魔法使いになりたい一心で、駄菓子屋に住み込み修行をはじめる。\n",
      "両親の仕事の都合上、親戚の珠江を頼って駄菓子屋ひよりへやってきた。\r\n"
     ]
    }
   ],
   "source": [
    "import urllib , requests , sys ,string ,time\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "\n",
    "#頁顯示數量\n",
    "pnum = 30\n",
    "mlink = 'http://www.dlsite.com/books/'\n",
    "\n",
    "fkey = open('key.txt', 'r')\n",
    "key = fkey.readline()#key=作者\n",
    "fkey.close()\n",
    "def Q2B(ustring):\n",
    "    fs=u'０１２３４５６７８９ＱｑＷｗＥｅＲｒＴｔＹｙＵｕＩｉＯｏＰｐＡａＳｓＤｄＦｆＧｇＨｈＪｊＫｋＬｌＺｚＸｘＣｃＶｖＢｂＮｎＭｍ'\n",
    "    hs=u'0123456789QqWwEeRrTtYyUuIiOoPpAaSsDdFfGgHhJjKkLlZzXxCcVvBbNnMm'\n",
    "    rstr = ''\n",
    "    for tm in ustring:\n",
    "        if fs.find(tm)+1:\n",
    "            tm = hs[fs.find(tm)]\n",
    "        rstr = rstr + tm\n",
    "    ustring = rstr\n",
    "    ustring=ustring.lower()\n",
    "    return ustring\n",
    "\n",
    "#def bfind(blink='http://www.dlsite.com/books/work/=/product_id/BJ041839.html'):\n",
    "#def bfind(blink='http://www.dlsite.com/pro/work/=/product_id/VJ009052.html'):\n",
    "def bfind(blink='http://www.dlsite.com/books/'):\n",
    "    global a\n",
    "    res = requests.get(blink)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    ssoup_1 = SoupStrainer(id=\"work_right\")#資訊欄位\n",
    "    ssoup_2 = SoupStrainer(class_=\"work_article work_story\")#內容欄位\n",
    "    \n",
    "    #only_a_tags = SoupStrainer(class_=\"work_article work_story\")#縮小處理範圍\n",
    "    #only_a_tags = SoupStrainer(['a','td'])#縮小處理範圍\n",
    "    #先html.parser解析與縮小範圍，再以字串給lxml\n",
    "    #soup = BeautifulSoup(str(BeautifulSoup(res.text,\"html.parser\",  parse_only=only_a_tags)),\"lxml\")\n",
    "    soup1 = BeautifulSoup(res.text,\"lxml\",  parse_only=ssoup_1)#資訊欄位\n",
    "    soup2=BeautifulSoup(res.text,\"lxml\",  parse_only=ssoup_2)#內容欄位\n",
    "    #print soup.text\n",
    "    #soup = BeautifulSoup(res.text, 'lxml', parse_only=SoupStrainer([\"main_genre\" , class_=\"work_genre\"]))\n",
    "    nnum1=''#作者出現次數\n",
    "    nnum2=''#作者出現次數\n",
    "    bdate1=''#含作者資料\n",
    "    bdate2=''#含作者資料\n",
    "    check=0\n",
    "    cname=''\n",
    "    \n",
    "    nnum1 = Q2B(soup1.text).encode('utf8').count(key)#作者出現次數\n",
    "    nnum2=Q2B(soup2.text).encode('utf8').count(key)\n",
    "    \n",
    "    #資訊欄位\n",
    "    for tm in soup1.select('tr'):\n",
    "        #print tm\n",
    "        #日期\n",
    "        if u'予告開始日' in tm.text:\n",
    "            #print 'ooooooooooooooooooooooooook',tm.td\n",
    "            check=1\n",
    "            cdata=tm.td.text\n",
    "        elif u'販売日' in tm.text:\n",
    "            cdata=tm.td.text\n",
    "        #類型\n",
    "        if u'作品形式'in tm.text:\n",
    "            ctype='['+tm.td.text+']'\n",
    "        #作者\n",
    "        ##作者不一定有<a>，棄用的方法。\n",
    "        #tmm=tm.select('a')#.get_text('//')\n",
    "        tmm=tm.td\n",
    "        tm=Q2B(tm.text).replace('\\n','')\n",
    "        #tm=Q2B(tm.get_text())\n",
    "        if key.decode('utf8') in tm:\n",
    "            \n",
    "            #for tmmm in tmm:\n",
    "                #cname=cname+tmmm.text+u'/'\n",
    "            #print tmm,len(tmm)\n",
    "            cname=Q2B(tmm.text).replace('\\n','')\n",
    "            bdate1=bdate1+tm+'_'\n",
    "    bdate1=bdate1[:-1]\n",
    "    #cname=Q2B(cname[:-1])\n",
    "    #print 'cname:',len(cname),cname\n",
    "    \n",
    "    #內容欄位\n",
    "    x=0\n",
    "    if nnum2 > 0:\n",
    "        tm=Q2B(soup2.text)\n",
    "        while tm.find(key.decode('utf8'))>-1:\n",
    "            #print 's2',tm[tm.rfind('\\n',0,tm.find(key))+1:tm.find('\\n',tm.find(key))]\n",
    "            #key前後\\n\n",
    "            bdate2=bdate2+'-'+tm[tm.rfind(u'\\n',0,tm.find(key.decode('utf8'))) : tm.find(u'\\n',tm.find(key.decode('utf8')))].strip(u'\\n')#+'\\n'\n",
    "            a=a+tm[tm.rfind(u'\\n',0,tm.find(key.decode('utf8'))) : tm.find(u'\\n',tm.find(key.decode('utf8')))]\n",
    "            #print tm.find(key),tm.rfind('\\n',0,tm.find(key)),tm.find('\\n',tm.find(key))\n",
    "            tm=tm[tm.find(key.decode('utf8'))+1:]\n",
    "            x=x+1\n",
    "            if x>5:\n",
    "                break\n",
    "    #\\n佔用兩格\n",
    "    bdate2=bdate2.rstrip('\\n')\n",
    "    #sou = BeautifulSoup(str(tr),\"lxml\")\n",
    "    #'''\n",
    "    \n",
    "    if int(nnum1) > 0:\n",
    "        check=5\n",
    "        if u'マンガ' in ctype:\n",
    "            check=2\n",
    "            if u'同人' in ctype:\n",
    "                check=4\n",
    "            elif key.decode('utf8') != cname:\n",
    "                check=3\n",
    "    elif nnum2 >0:\n",
    "    #else:\n",
    "        if u'マンガ' in ctype:\n",
    "            check=6\n",
    "        else:\n",
    "            check=7\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    1新\n",
    "    2漫單\n",
    "    3漫多\n",
    "    4漫同人\n",
    "    5它\n",
    "    6漫\n",
    "    7它\n",
    "    1>4>3>2\n",
    "    \n",
    "    新\n",
    "    合1:漫_漫多_同_它\n",
    "    合2:漫_非\n",
    "    #'''\n",
    "    \n",
    "    #print 'bfind'\n",
    "    \n",
    "    #類型_nnum1_bdate1_nnum2_bdate2_check\n",
    "    #return cdata,ctype,nnum1,bdate1,nnum2,bdate2\n",
    "    print type(nnum2),type(nnum1)\n",
    "    return ctype,nnum1,bdate1,nnum2,bdate2,check\n",
    "\n",
    "##############################\n",
    "a=u''\n",
    "#key='games'\n",
    "#c1=bfind('http://www.dlsite.com/books/work/=/product_id/BJ011458.html')\n",
    "c2=bfind('http://www.dlsite.com/pro/work/=/product_id/VJ006967.html')\n",
    "#c3=bfind('http://www.dlsite.com/books/work/=/product_id/BJ043185.html')\n",
    "print '########catch:',len(c2)#,cfind[:]\n",
    "#b1=c1[4]\n",
    "b2=c2[4]\n",
    "#b3=c3[4]\n",
    "\n",
    "#print c1[4][:]+'_\\n'+c2[4]+'_\\n'+c3[4]+'_\\n'\n",
    "print b2[2:22]+'_\\n',len(b2)\n",
    "print type(b2),len(b2)\n",
    "B2=b2.encode('utf8')\n",
    "print type(B2),len(B2)\n",
    "print B2\n",
    "print '###',a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
