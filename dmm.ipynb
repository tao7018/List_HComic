{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "ok\n",
      "BIG\n",
      "奥森ボウイ 85 num\n",
      "========v1\n",
      "page:1\n",
      "2 単話 俺得修学旅行〜男は女装した俺だけ！ 奥森ボウイ 2 _ 10 b278agphg00378\n",
      "3 単話 【セット】俺得修学旅行〜男は女装した俺だけ 奥森ボウイ 1 _ 2 b266agrph00295\n",
      "5 単話 パイパイちょうだい！！〜六畳一間でミルクをちゅっちゅ〜 奥森ボウイ_赤髭 1 _ 2 b924akgky01101\n",
      "8 単話 夏色バズー 奥森ボウイ 0 _  b336afjcb00458\n",
      "11 単話 パイパイちょうだい！！〜六畳一間でミルクをちゅっちゅ 奥森ボウイ_赤髭 1 _ 2 b924akgky00894\n",
      "17 単話 【セット】鬼畜美少女狩り〜禁断の 奥森ボウイ 0 _  b266agrph00180\n",
      "19 単話 踊る誘惑受付嬢〜ありえない腰使い〜 奥森ボウイ 0 _  b924akgky00838\n",
      "20 単行本 今回はご縁ありました、ということ 奥森ボウイ 0 _  b216afjm00389\n",
      "21 単話 ちっぱいフーゾク嬢と野外えっち！ 奥森ボウイ_kupa 0 _  b604atppn00003\n",
      "25 単話 トナリノ 奥森ボウイ 0 _  b336afjcb00388\n",
      "28 単話 情熱は踊る 奥森ボウイ 0 _  b336afjcb00366\n",
      "30 単話 鬼畜美少女狩り〜禁断の復 奥森ボウイ 1 _ 4 b278agphg00268\n",
      ".\n",
      "page:2\n",
      "1 単行本 放課後ふたりぼ 奥森ボウイ 0 _  b257bdmmg00243\n",
      "3 単話 スタンド・バイ・ミ 奥森ボウイ 0 _  b257bdmmg00228\n",
      "5 単話 俺の彼女はすーぱーぷに 奥森ボウイ 0 _  b336afjcb00341\n",
      "7 単話 感じて、カテキョ〜いつやるの？今でしょ！〜 奥森ボウイ_赤髭 1 _ 2 b924akgky00477\n",
      "8 単話 マンマンちょうだい！！〜義母さんは、同級生！？〜 奥森ボウイ_赤髭 1 _ 2 b924akgky00407\n",
      "9 単話 マンマンちょうだい！！〜義母さんは、同級生！？ 奥森ボウイ_赤髭 1 _ 2 b924akgky00548\n",
      "12 単話 演じて感じ 奥森ボウイ 0 _  b336afjcb00320\n",
      "15 単話 グラドルが堕ちた 奥森ボウイ 0 _  b336afjcb00296\n",
      "18 単話 出張！薊野学園生徒会長がイクッ 奥森ボウイ 0 _  b257bdmmg00137\n",
      "20 単話 エンジェル★イヤ 奥森ボウイ 0 _  b336afjcb00273\n",
      "22 単話 劣情優等 奥森ボウイ 0 _  b336afjcb00262\n",
      "24 単話 美魔女特 奥森ボウイ 0 _  b336afjcb00252\n",
      "26 単話 徒花が咲く頃 奥森ボウイ 0 _  b336afjcb00241\n",
      "30 単話 今回はご縁がありましたということ 奥森ボウイ 0 _  b335afjps00304\n",
      ".\n",
      "page:3\n",
      "5 単話 アイドリング・ノン・ストッ 奥森ボウイ 0 _  b335afjps00279\n",
      "6 単話 感じて、カテキョ〜いつやるの？今でしょ！ 奥森ボウイ_赤髭 1 _ 2 b924akgky00188\n",
      "13 単話 踊る誘惑受付嬢〜ありえない腰使い 奥森ボウイ 0 _  b924akgky00139\n",
      "15 単話 ハッピーホリデイ☆ワーキン 奥森ボウイ 0 _  b336afjcb00216\n",
      "17 単話 純白仕上げのクリーニング娘 奥森ボウイ 0 _  b336afjcb00199\n",
      "19 単話 やりすぎツインテー 奥森ボウイ 0 _  b336afjcb00181\n",
      "21 単話 恋して ガッテ 奥森ボウイ 0 _  b336afjcb00167\n",
      "23 単話 ばきゅ～むmm 奥森ボウイ 0 _  b336afjcb00149\n",
      "25 単話 MAGIC！ 奥森ボウイ 0 _  b336afjcb00119\n",
      ".\n",
      "ok\n",
      "3 .. 2 .. 1 ..\n",
      "Press Any Key To Exit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import urllib , requests , sys ,string ,time\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "from time import gmtime, strftime\n",
    "\n",
    "#dmm\n",
    "#fkey作者來源key.txt\n",
    "#fcomiclist結果key_dmm.text\n",
    "\n",
    "#輸出格式：\n",
    "#dmm\n",
    "#!作者\n",
    "#!總筆數\n",
    "#==類別_數量_中文敘述\n",
    "#[同人團_作者群][原作][同人場cXX]同人作品\n",
    "#參考網址\n",
    "\n",
    "#頁顯示數量\n",
    "pnum = 30\n",
    "mlink = 'http://book.dmm.co.jp/'\n",
    "\n",
    "fkey = open('key.txt', 'r')\n",
    "key = fkey.readline()#key=作者\n",
    "fkey.close()\n",
    "\n",
    "#key=作者\n",
    "key2 = urllib.quote(key.decode('utf8').encode('shift_jis'))#當sjis輸出utf8的url\n",
    "key3 = urllib.unquote(key2.decode('shift_jis').encode('utf8'))#utf8的url翻sjis\n",
    "#網址用\n",
    "key4 = urllib.quote(key)\n",
    "\n",
    "#檢查BOM\n",
    "if '%EF%BB%BF' in urllib.quote(key):\n",
    "    print 'fuck ms'\n",
    "\n",
    "'''\n",
    "http://www.dmm.co.jp/search/=\n",
    "/searchstr=%E5%A5%A5%E6%A3%AE%E3%83%9C%E3%82%A6%E3%82%A4#作者\n",
    "/analyze=V1EBD1YFUAM_#可省略?\n",
    "/limit=30#頁顯示數量\n",
    "/n1=FgRCTw9VBA4GAFNXXF0_\n",
    "/sort=date#排序\n",
    "/view=text#檢視模式_有無\n",
    "/page=2#頁_P1沒有\n",
    "/#尾\n",
    "'''\n",
    "#page=1\n",
    "link=\"http://www.dmm.co.jp/search/=/\\\n",
    "searchstr=\"+key4+\"/limit=30/n1=FgRCTw9VBA4GAFNXXF0_/sort=date/\"\n",
    "#標題與話數_http://book.dmm.co.jp/detail/b333afjpc00714/\n",
    "\n",
    "res = requests.get(link)\n",
    "res.encoding =  res.apparent_encoding#亂碼處理\n",
    "r= res.text\n",
    "#r=r[r.find(u'<td id=\"mu\">'):r.find(u'<!-- /mu --></td>')+len(u'<!-- /mu --></td>')]#+'</td>'#搜尋結果擷取\n",
    "r=r[r.find(u'</div><![endif]-->')+len(u'</div><![endif]-->'):r.find(u'<div id=\"footer\">')]#+'</td>'#搜尋結果擷取\n",
    "\n",
    "\n",
    "#only_a_tags = SoupStrainer(id=\"mu\")#縮小檢索範圍\n",
    "soup = BeautifulSoup(r,\"lxml\")#,  parse_only=only_a_tags)\n",
    "\n",
    "def next(page = 2):\n",
    "    #page=int(page)\n",
    "    #ps=page*pnum+1\n",
    "    link=\"http://www.dmm.co.jp/search/=/\\\n",
    "    searchstr=\"+key4+\"/limit=30/n1=FgRCTw9VBA4GAFNXXF0_/sort=date/\"\n",
    "    \n",
    "    if page>1:\n",
    "        link=link+'page='+str(page)+'/'\n",
    "    \n",
    "    res = requests.get(link)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    r= res.text\n",
    "    r=r[r.find(u'</div><![endif]-->')+len(u'</div><![endif]-->'):r.find(u'<div id=\"footer\">')]#+'</td>'#搜尋結果擷取\n",
    "    \n",
    "    #先html.parser解析與縮小範圍，再以字串給lxml\n",
    "    #only_a_tags = SoupStrainer(id=\"mu\")#縮小檢索範圍\n",
    "    soup = BeautifulSoup(r,\"lxml\")#,  parse_only=only_a_tags)\n",
    "    \n",
    "    return soup\n",
    "\n",
    "#全轉半\n",
    "def Q2B(ustring):\n",
    "    fs=u'０１２３４５６７８９ＱｑＷｗＥｅＲｒＴｔＹｙＵｕＩｉＯｏＰｐＡａＳｓＤｄＦｆＧｇＨｈＪｊＫｋＬｌＺｚＸｘＣｃＶｖＢｂＮｎＭｍ'\n",
    "    hs=u'0123456789QqWwEeRrTtYyUuIiOoPpAaSsDdFfGgHhJjKkLlZzXxCcVvBbNnMm'\n",
    "    rstr = ''\n",
    "    for tm in ustring:\n",
    "        if fs.find(tm)+1:\n",
    "            tm = hs[fs.find(tm)]\n",
    "        rstr = rstr + tm\n",
    "    ustring = rstr\n",
    "    ustring=ustring.lower()\n",
    "    return ustring\n",
    "#半轉全\n",
    "def B2Q(ustring):\n",
    "    fs=u'０１２３４５６７８９ＱｑＷｗＥｅＲｒＴｔＹｙＵｕＩｉＯｏＰｐＡａＳｓＤｄＦｆＧｇＨｈＪｊＫｋＬｌＺｚＸｘＣｃＶｖＢｂＮｎＭｍ'\n",
    "    hs=u'0123456789QqWwEeRrTtYyUuIiOoPpAaSsDdFfGgHhJjKkLlZzXxCcVvBbNnMm'\n",
    "    rstr = ''\n",
    "    ustring=ustring.lower()\n",
    "    for tm in ustring:\n",
    "        if hs.find(tm)+1:\n",
    "            tm = fs[hs.find(tm)]\n",
    "        rstr = rstr + tm\n",
    "    ustring = rstr\n",
    "    return ustring\n",
    "\n",
    "#資料儲存\n",
    "def save(sdict , check=0):\n",
    "    for temp in listdata:\n",
    "        if sdict.get(temp):\n",
    "            fout.write(sdict[temp].encode('utf8')  + '\\n')\n",
    "    #return\n",
    "\n",
    "#作品頁面\n",
    "def finddata(dlink):\n",
    "    res = requests.get(dlink)#,cookies=cookies)\n",
    "    res.encoding =  res.apparent_encoding#亂碼處理\n",
    "    r= res.text\n",
    "    r=r[r.find(u'</div><![endif]-->')+len(u'</div><![endif]-->'):r.find(u'<div id=\"footer\">')]#+'</td>'#搜尋結果擷取\n",
    "    \n",
    "    #only_a_tags = SoupStrainer(\"table\", summary=\"Details\")#縮小檢索範圍\n",
    "    sou=BeautifulSoup(r,\"lxml\")#,  parse_only=only_a_tags)\n",
    "    #dname=sou.select('.m-boxDetailProductInfoMainList__description__list')[0].text\n",
    "    \n",
    "    dname=u''\n",
    "    dbook=u''\n",
    "    dcheck=0\n",
    "    for d in sou.select('.m-boxDetailProductInfoMainList__description__list')[0].select('a'):\n",
    "        if d.text==key.decode('utf8'):\n",
    "            dcheck=1\n",
    "            #print 'd'\n",
    "        dname=dname+'_'+d.text\n",
    "    #print 'find',dbook,dname\n",
    "    dname=dname.strip(u'_')\n",
    "    dbook=sou.select('.m-boxDetailProductInfoMainList__description__list')[1].text.strip().strip(u'\\n').strip(u'\\t')\n",
    "    if dcheck==1 :\n",
    "        if key.decode('utf8') != dname:\n",
    "            dcheck=3\n",
    "            #print 'dd'\n",
    "    '''\n",
    "    dname=sou.select('.DetailData_L')[2].text#作者\n",
    "    draw=sou.select('.DetailData_L')[3].text#同人原作\n",
    "    dtype=sou.select('.DetailData_R')[0].text#類型\n",
    "    ddate=sou.select('.DetailData_R')[1].text#日期\n",
    "    \n",
    "    dname=Q2B(dname.strip().strip(u'\\n').replace('\\n',' ').replace('\\t',''))\n",
    "    draw=draw.strip().strip(u'\\n').replace('\\n','').replace('\\t','')\n",
    "    #print dname,draw,dtype,ddate\n",
    "    #'''\n",
    "    return dname,dbook,dcheck\n",
    "\n",
    "#資料處理\n",
    "def findbook(soup , page = 1):\n",
    "    global bl\n",
    "    a =0\n",
    "    check = 0\n",
    "    for n in soup.select('.m-boxListBookProduct__item'):\n",
    "        cbook=n.select('.m-boxListBookProductTmb__ttl')[0].text\n",
    "        ctype=n.select('.m-boxListGenreIco.m-boxListGenreIco--large')[0].text\n",
    "        cbn=''#卷\n",
    "        cname=Q2B(n.select('.m-boxListBookProductTmb__linkAuthor')[0].text.strip().strip(u'\\n'))\n",
    "        #網址\n",
    "        clink=n.select('.m-boxListBookProductTmb')[0].select('a')[0].get('href')\n",
    "        \n",
    "        a=a+1\n",
    "        print '\\r',a,\n",
    "        \n",
    "        #類別\n",
    "        #if (u'' == ctype):\n",
    "        if u'単行本' == ctype:\n",
    "            check=1#單行本\n",
    "        elif u'単話' ==ctype:\n",
    "            check=2#單話\n",
    "        else:\n",
    "            continue#目標外\n",
    "        \n",
    "        #作品頁_1標題2作者3系列\n",
    "        if (u'...' in cbook)or(key.decode('utf8') !=cname):#or():\n",
    "            #print 'findbook'\n",
    "            cname,cbook,dcheck=finddata(clink)\n",
    "            #print dcheck,'D'\n",
    "            if dcheck>2:\n",
    "                check=3#多作者\n",
    "            elif dcheck==0:\n",
    "                continue#非作者\n",
    "        \n",
    "        #作品名\n",
    "        cbook=cbook[:cbook.rfind(u'（単話）')]\n",
    "        cbook=cbook[:cbook.rfind(u'【フルカラー】')]\n",
    "        \n",
    "        #卷\n",
    "        if n.select('.m-boxListBookProductTmbSub.m-boxListBookTmbSubInfo--series'):\n",
    "            cbn=n.select('.m-boxListBookProductTmbSub.m-boxListBookTmbSubInfo--series')[0].text\n",
    "            cbn=cbn[2:cbn.find(u'卷')]    \n",
    "        \n",
    "        cdata=clink[len(u'http://book.dmm.co.jp/detail/'):-1]#網址當排序依據\n",
    "        \n",
    "        print ctype,cbook,cname,len(cbn),'_',cbn,cdata#,clink#,soup.select('.m-boxListBookProduct__item')[a]\n",
    "        #print 'check',check\n",
    "        #break\n",
    "        \n",
    "        #data處理\n",
    "        if len(cdata) < 3:#無data\n",
    "            cdata = '0000/00/00'#填入data\n",
    "            check = 4#\n",
    "        data = cdata\n",
    "        while listdata.count(data):#重複data判斷\n",
    "            data = data[:-2] + str(int(data[-2:]) + 1).rjust(2,'0')#尾數+1_十位數填0\n",
    "        listdata.append(data)\n",
    "        \n",
    "        book=cbook\n",
    "        btype=ctype\n",
    "        name=cname\n",
    "        bn=cbn\n",
    "        blink=clink\n",
    "        \n",
    "        #【セット】\n",
    "        #【フルカラー】（単話）\n",
    "        #寫入dict\n",
    "        if (len(bn)>0) or (check==3) or (u'【セット】' in book):\n",
    "            if len(bn)>0:\n",
    "                book=book+u'['+bn+u']'\n",
    "            book=book+'_!'+blink\n",
    "        #print book\n",
    "        \n",
    "        if check==1:#單行本\n",
    "            dict1.setdefault(data,book)\n",
    "        elif check==2:#單話\n",
    "            dict2.setdefault(data,book)\n",
    "        else:#多作者\n",
    "            book=u'['+name+u']['+btype+u']_'+book\n",
    "            dict3.setdefault(data,book)\n",
    "        \n",
    "        #club=cclub.strip().strip(u'\\n').replace('\\n','')\n",
    "        continue\n",
    "    print '.'\n",
    "    #print '========'\n",
    "    #return\n",
    "\n",
    "########\n",
    "\n",
    "key=key.lower()\n",
    "pn=0\n",
    "\n",
    "tmp=soup.select('.m-boxPagenation__txt')[0].text\n",
    "pn=tmp[tmp.find(u'全')+1:-1]#資料筆數\n",
    "print pn\n",
    "\n",
    "'''\n",
    "アダルトコミック\n",
    "美少女ノベル・官能小説\n",
    "アダルト写真集・雑誌\n",
    "#美少女ノベル_コミック雑誌\n",
    "#小說與寫真無法區分，皆不記錄。\n",
    "含小說_ぽるのいぶき\n",
    "含寫真_奥森ボウイ\n",
    "\n",
    "単行本\n",
    "単話\n",
    "コミック雑誌\n",
    "#【セット】\n",
    "\n",
    "#標題切斷範例_奥森ボウイ\n",
    "#多作者_LINDA\n",
    "#'''\n",
    "\n",
    "#資料筆數_是否數字\n",
    "if pn>0:\n",
    "    print 'ok'\n",
    "    #print soup.find_all('b')\n",
    "    \n",
    "    if pn > pnum:\n",
    "        print 'BIG'\n",
    "    \n",
    "    fout = open('output/'+key.decode('utf8') + '_dmmv1.txt', 'w')#寫入模式開檔\n",
    "    fout.write('dmm\\n')#toranoana\n",
    "    print key , pn , 'num\\n========v1'\n",
    "    time.sleep(1)\n",
    "    fout.write('!' + key + '\\n!總筆數' + str(pn).encode('utf8') +'_'+ strftime(\"%Y/%m/%d,%H:%M\")+'->')\n",
    "    \n",
    "    p = 0#頁\n",
    "    #建空輸出用字典與陣列\n",
    "    dict1={}#單行本\n",
    "    dict2={}#單話\n",
    "    dict3={}#多作者\n",
    "    listdata = []\n",
    "    bl=0#bl作品數\n",
    "    \n",
    "    #資料處理\n",
    "    while (int(pn) - p * pnum) > 0:\n",
    "        p = p + 1\n",
    "        print 'page:' + str(p)\n",
    "        soup = next(p)#頁\n",
    "        #print soup.select('.TBLdtil')[2]\n",
    "        findbook(soup)#資料處理\n",
    "        time.sleep(1)\n",
    "        #sys.exit()################\n",
    "    \n",
    "    #日期排序\n",
    "    listdata.sort()\n",
    "    \n",
    "    fout.write(strftime(\"%H:%M\")+'\\n')\n",
    "    \n",
    "    temp = ''\n",
    "    #dict1_單行本\n",
    "    fout.write('==book_' + str(len(dict2)) +'_單行本\\n')\n",
    "    save(dict1)\n",
    "    #dict2_單話\n",
    "    fout.write('==sbook_' + str(len(dict1)) +'_單話\\n')\n",
    "    save(dict2)\n",
    "    #dict3_多作者\n",
    "    fout.write('==other_' + str(len(dict1)) +'_多作者\\n')\n",
    "    save(dict3)\n",
    "    \n",
    "    #sys.exit()################\n",
    "    fout.close()\n",
    "    print 'ok'\n",
    "elif pn:\n",
    "    print 'No Date'\n",
    "\n",
    "#結束讀秒\n",
    "x=3\n",
    "while x!=0:\n",
    "    print x,'..',\n",
    "    x=x-1\n",
    "    time.sleep(1)\n",
    "raw_input(\"\\nPress Any Key To Exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106547 \n",
      "61378\n",
      "85\n",
      "85\n",
      "コミック雑誌 null\n",
      "1 俺得修学旅行～男は女装し... 単話 2 奥森ボウイ 1～10巻\n",
      "2 【セット】俺得修学旅行～... 単話 2 奥森ボウイ 1～2巻\n",
      "コミック雑誌 null\n",
      "4 パイパイちょうだい！！～... 単話 2 奥森ボウイ 他 1～2巻\n",
      "コミック雑誌 null\n",
      "コミック雑誌 null\n",
      "7 夏色バズーカ（単話） 単話 2 奥森ボウイ \n",
      "コミック雑誌 null\n",
      "コミック雑誌 null\n",
      "10 パイパイちょうだい！！～... 単話 2 奥森ボウイ 他 1～2巻\n",
      "美少女ノベル null\n",
      "コミック雑誌 null\n",
      "美少女ノベル null\n",
      "美少女ノベル null\n",
      "美少女ノベル null\n",
      "16 【セット】鬼畜美少女狩り... 単話 2 奥森ボウイ \n",
      "コミック雑誌 null\n",
      "18 踊る誘惑受付嬢～ありえな... 単話 2 奥森ボウイ \n",
      "19 今回はご縁ありました、と... 単行本 3 奥森ボウイ \n",
      "20 ちっぱいフーゾク嬢と野外... 単話 2 奥森ボウイ 他 \n",
      "コミック雑誌 null\n",
      "コミック雑誌 null\n",
      "コミック雑誌 null\n",
      "24 トナリノ女（単話） 単話 2 奥森ボウイ \n",
      "コミック雑誌 null\n",
      "コミック雑誌 null\n",
      "27 情熱は踊る♪（単話） 単話 2 奥森ボウイ \n",
      "コミック雑誌 null\n",
      "29 鬼畜美少女狩り～禁断の復... 単話 2 奥森ボウイ 1～4巻\n",
      "\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndbook=soup.select('.m-boxDetailProductInfoMainList__description__list')[1].select('a')[0].text\\nfor d in soup.select('.m-boxDetailProductInfoMainList__description__list')[0].select('a'):\\n    print d.text\\nprint dbook\\n#\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import urllib , requests , sys ,string ,time\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "from time import gmtime, strftime\n",
    "\n",
    "fkey = open('key.txt', 'r')\n",
    "key = fkey.readline()#key=作者\n",
    "fkey.close()\n",
    "\n",
    "c='''\n",
    "<li class=\"m-boxListBookProductTmbSub m-boxListBookTmbSubInfo--series\"><span class=\"m-boxListBookTmbSubInfo__txt m-boxListBookTmbSubInfo--series__txt\"><a href=\"http://book.dmm.co.jp/series/?floor=Abook&series_id=559179\">1～2巻</a></span></li>\n",
    "                <li class=\"m-boxListBookProductTmbSub m-boxListBookProductTmbSub--price\">\n",
    "                    <span class=\"m-boxListBookProductTmbSub__txt m-boxListBookProductTmbSub--price__txt\">\n",
    "                        324円                    </span>\n",
    "                </li>\n",
    "'''\n",
    "\n",
    "#key=作者\n",
    "key2 = urllib.quote(key.decode('utf8').encode('EUC_JP'))#當sjis輸出utf8的url\n",
    "key3 = urllib.unquote(key2.decode('shift_jis').encode('utf8'))#utf8的url翻sjis\n",
    "#網址用\n",
    "key4 = urllib.quote(key)\n",
    "'''\n",
    "http://www.dmm.co.jp/search/=\n",
    "/searchstr=%E5%A5%A5%E6%A3%AE%E3%83%9C%E3%82%A6%E3%82%A4\n",
    "/analyze=V1EBD1YFUAM_#可省略?\n",
    "/limit=30#頁顯示數量\n",
    "/n1=FgRCTw9VBA4GAFNXXF0_\n",
    "/sort=date#排序\n",
    "/view=text#檢視模式_有無\n",
    "/page=2#頁_P1沒有\n",
    "/#尾\n",
    "'''\n",
    "page=1\n",
    "link=\"http://www.dmm.co.jp/search/=/\\\n",
    "searchstr=\"+key4+\"/limit=30/n1=FgRCTw9VBA4GAFNXXF0_/sort=date/\"\n",
    "#link='http://book.dmm.co.jp/detail/b924akgky01101/'\n",
    "#標題與話數_http://book.dmm.co.jp/detail/b333afjpc00714/\n",
    "if page>1:\n",
    "    link=link+'page='+str(page)+'/'\n",
    "\n",
    "res = requests.get(link)\n",
    "res.encoding =  res.apparent_encoding#亂碼處理\n",
    "r= res.text\n",
    "#r=r[r.find(u'<td id=\"mu\">'):r.find(u'<!-- /mu --></td>')+len(u'<!-- /mu --></td>')]#+'</td>'#搜尋結果擷取\n",
    "r=r[r.find(u'</div><![endif]-->')+len(u'</div><![endif]-->'):r.find(u'<div id=\"footer\">')]#+'</td>'#搜尋結果擷取\n",
    "#r='<html><body><table>'+r+'</table></body></html>'\n",
    "#r=r[r.find(u'<!-- MAIN AREA -->'):r.rfind(u'</table>')+len(u'</table>')]#搜尋結果擷取\n",
    "#print r\n",
    "\n",
    "#only_a_tags = SoupStrainer(id=\"mu\")#縮小檢索範圍\n",
    "#soup = BeautifulSoup(r,\"html.parser\")#,  parse_only=only_a_tags)\n",
    "soup = BeautifulSoup(r,\"lxml\")#,  parse_only=only_a_tags)\n",
    "\n",
    "#'''\n",
    "print len(res.text),'\\n',len(str(soup))#,len(str(sou))\n",
    "#print soup,str(soup)\n",
    "tmp=soup.select('.m-boxPagenation__txt')[0].text\n",
    "pn=tmp[tmp.find(u'全')+1:-1]#搜尋筆數\n",
    "print pn\n",
    "if len(str(soup))>100:\n",
    "    tmp=soup.select('.m-boxPagenation__txt')[0].text\n",
    "    pn=tmp[tmp.find(u'全')+1:-1]#搜尋筆數\n",
    "    print pn\n",
    "\n",
    "a=0\n",
    "for n in soup.select('.m-boxListBookProduct__item'):\n",
    "    cbook=n.select('.m-boxListBookProductTmb__ttl')[0].text\n",
    "    ctype=n.select('.m-boxListGenreIco.m-boxListGenreIco--large')[0].text\n",
    "    cbn=''#卷\n",
    "    cname=n.select('.m-boxListBookProductTmb__linkAuthor')[0].text.strip().strip(u'\\n')\n",
    "    \n",
    "    #作品頁_1標題2作者3系列\n",
    "    if n.select('.m-boxListBookProductTmbSub.m-boxListBookTmbSubInfo--series'):\n",
    "        cbn=n.select('.m-boxListBookProductTmbSub.m-boxListBookTmbSubInfo--series')[0].text\n",
    "    #cbn=n.select('.m-boxListBookProductTmbSub.m-boxListBookTmbSubInfo--series')#[0].text\n",
    "    if (u'美少女ノベル' == ctype) or (u'コミック雑誌' == ctype):\n",
    "        print ctype,'null'\n",
    "    else:\n",
    "        print a,cbook,ctype,len(ctype),cname,cbn#,soup.select('.m-boxListBookProduct__item')[a]\n",
    "    a=a+1\n",
    "#print key4\n",
    "print '\\n.'\n",
    "#'''\n",
    "\n",
    "'''\n",
    "dbook=soup.select('.m-boxDetailProductInfoMainList__description__list')[1].select('a')[0].text\n",
    "for d in soup.select('.m-boxDetailProductInfoMainList__description__list')[0].select('a'):\n",
    "    print d.text\n",
    "print dbook\n",
    "#'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
