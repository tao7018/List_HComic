{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==daito-i 20 筆\n",
      "page:0\n",
      "http://www.daito-i.com/top/show_unit.php?mode=search&category=&subcategory=&search_cat=&keyword=%E5%85%AB%E8%89%B2&sort=&page_num=0\n",
      "20\n",
      "0 .\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import urllib , requests , sys , string   ,time , os\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "from time import gmtime , strftime\n",
    "\n",
    "'''\n",
    "daito-i\n",
    "\n",
    "daito_i.txt\n",
    "#無書目例#http://www.daito-i.com/top/comics/detail.php?code=9784344805408\n",
    "#有圖http://www.daito-i.com/top/comics/detail.php?code=9784799206096\n",
    "'''\n",
    "\n",
    "#全轉半\n",
    "def Q2B(ustring):\n",
    "    fs=u'０１２３４５６７８９ＱｑＷｗＥｅＲｒＴｔＹｙＵｕＩｉＯｏＰｐＡａＳｓＤｄＦｆＧｇＨｈＪｊＫｋＬｌＺｚＸｘＣｃＶｖＢｂＮｎＭｍ'\n",
    "    hs=u'0123456789QqWwEeRrTtYyUuIiOoPpAaSsDdFfGgHhJjKkLlZzXxCcVvBbNnMm'\n",
    "    rstr = ''\n",
    "    for tm in ustring:\n",
    "        if fs.find(tm)+1:\n",
    "            tm = hs[fs.find(tm)]\n",
    "        rstr = rstr + tm\n",
    "    ustring = rstr\n",
    "    ustring=ustring.lower()\n",
    "    return ustring\n",
    "\n",
    "#資料儲存\n",
    "def save(fout , listdata , sdict , check=0):\n",
    "    for tep in listdata:\n",
    "        if sdict.get(tep):\n",
    "            fout.write(sdict[tep]  + '\\n')\n",
    "    #return\n",
    "\n",
    "#單行本\n",
    "def find_b(blink, key, bdict2):\n",
    "    res = requests.get(blink)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    only_a_tags = SoupStrainer(class_=\"goodTxt\")\n",
    "    soup = BeautifulSoup(res.text ,\"lxml\",  parse_only=only_a_tags)\n",
    "    \n",
    "    bdata = ''\n",
    "    nnum= 0\n",
    "    nnum = str(soup).count('<br/>')#<br/>次數\n",
    "    for tm in soup.select('p'):\n",
    "        if (str(tm).count('<br/>') > 5):\n",
    "            bdata = bdata + '(' + str(str(tm).count('<br/>')) + ')-'#換行次數當單行本話數\n",
    "            bdict2 = bdict2 + tm.get_text('_') + '_'#比對用疊加\n",
    "            bdata = bdata + tm.get_text('\\n-') + '%\\n'\n",
    "        bdata = bdata.strip('\\n')\n",
    "    return bdata,nnum,bdict2\n",
    "#雜誌類\n",
    "def find_m(blink, key, listdict3):\n",
    "    res = requests.get(blink)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    only_a_tags = SoupStrainer(class_=\"goodTxt\")\n",
    "    soup = BeautifulSoup(res.text ,\"lxml\",  parse_only=only_a_tags)\n",
    "    \n",
    "    bdata = ''\n",
    "    nnum=0\n",
    "    nnum = Q2B(soup.text).encode('utf8').count(key)#作者出現次數\n",
    "    for tm in soup.select('p'):\n",
    "        if (str(tm).count('】') > 4):#特徵\n",
    "            tt=Q2B(tm.text).strip().strip('\\n').replace('\\t','').split(u'】')\n",
    "            for t in tt:\n",
    "                if key.decode('utf8') in t[t.find(u'【')+1:]:\n",
    "                    listdict3.append(t[:t.find(u'【')])#比對用疊加\n",
    "                    bdata= bdata+ t[:t.find(u'【')]\n",
    "                    if key.decode('utf8') != t[t.find(u'【')+1:]:\n",
    "                        bdata= bdata+ '['+ t[t.find(u'【')+1:]+ ']'\n",
    "                    bdata= bdata+ '_'\n",
    "            bdata=bdata.strip('_')\n",
    "    return bdata,nnum,listdict3\n",
    "\n",
    "#資料處理\n",
    "def findbook(dictB, listdata, listdict3, receive):\n",
    "    link, key, p, pn, pnn, olddate, bdict2=receive\n",
    "    mlink = 'http://www.daito-i.com/top/'\n",
    "    if len(link)<5:\n",
    "        return dictB, listdata, listdict3, pnn, olddate, bdict2\n",
    "    \n",
    "    res = requests.get(link)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    r= res.text\n",
    "    r=r[r.find(u'<!-- ▼mainContents -->'):r.find(u'<!-- ▲mainContents -->')+len(u'<!-- ▲mainContents -->')]\n",
    "    soup = BeautifulSoup(r ,\"lxml\")#,  parse_only=only_a_tags)\n",
    "    \n",
    "    bn=len(soup.select('.itmBox'))-len(soup.find_all(src=\"images/dummy.jpg\"))\n",
    "    \n",
    "    a =0\n",
    "    for tm in soup.select('.itmBox')[:bn]:\n",
    "        if pnn==0:\n",
    "            return dictB, listdata, listdict3, pnn, olddate, bdict2\n",
    "        pnn=pnn-1\n",
    "        a=a+1\n",
    "        print '\\r',pnn,\n",
    "        \n",
    "        check=0\n",
    "        cdata=''\n",
    "        ctype= tm.div.next_sibling.strip(' \\n')\n",
    "        cname = Q2B(tm.select('a')[2].text)\n",
    "        \n",
    "        if ctype== u'予約商品':\n",
    "            check= 1\n",
    "        elif ctype== u'コミックス' and key.decode('utf8') in cname:\n",
    "            check= 2\n",
    "        elif (ctype== u'雑誌') or (ctype== u'コミックス' and cname == u'アンソロジー'):\n",
    "            check= 3\n",
    "        elif ctype in [u'ノベルズ', u'文庫']:\n",
    "            check= 4\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        cbook = tm.select('a')[1].text\n",
    "        clink = tm.select('a')[0].get('href')\n",
    "        blink = mlink + clink\n",
    "        \n",
    "        if check== 2:\n",
    "            cdata, nnum, bdict2= find_b(blink, key, bdict2)#book\n",
    "            if len(cdata) < 10:\n",
    "                cdata = 'lost'\n",
    "        elif check== 3:\n",
    "            cdata, nnum, listdict3= find_m(blink, key, listdict3)#magazine\n",
    "        \n",
    "        listdata.append(pnn)\n",
    "        \n",
    "        cbook = cbook.encode('utf8')\n",
    "        ctype = ctype.encode('utf8')\n",
    "        cname = cname.encode('utf8')\n",
    "        cdata = cdata.encode('utf8')\n",
    "        \n",
    "        if check==1:#新刊\n",
    "            book = cname + '_' + cbook + '_\\n!' + blink\n",
    "            dictB[\"dict1\"].setdefault(pnn,book)\n",
    "        elif check==2:#單行本\n",
    "            if key.decode('utf8') != cname:#多作者\n",
    "                cbook= cbook+'['+ cname+ ']'\n",
    "            book = cbook + '_\\n' + cdata + '\\n!' + blink\n",
    "            dictB[\"dict2\"].setdefault(pnn,book)\n",
    "        elif check==3:#雜誌\n",
    "            book = cbook + '[' + cname + ']_' + cdata + '_\\n!' + str(nnum) + '!' + blink\n",
    "            dictB[\"dict3\"].setdefault(pnn,book)\n",
    "        elif check==4:#其他\n",
    "            book = ctype + '_' + cname + '_' + cbook + '_\\n!' + blink\n",
    "            dictB[\"dict4\"].setdefault(pnn,book)\n",
    "        \n",
    "        if a==(bn):\n",
    "            break\n",
    "        #continue\n",
    "    print '.'\n",
    "    #print '========'\n",
    "    return dictB, listdata, listdict3, pnn, olddate, bdict2\n",
    "\n",
    "########\n",
    "def main(key='',ucheck=0,pn=0,nlink=''):\n",
    "    #ucheck_0建檔_1更新_2直讀\n",
    "    \n",
    "    pnum = 30#頁顯示數量\n",
    "    mlink = 'http://www.daito-i.com/top/'#前綴網址\n",
    "    \n",
    "    olddate=''\n",
    "    if ucheck != 2:\n",
    "        #key=作者\n",
    "        key=key.lower()\n",
    "        key2 = urllib.quote(key.decode('utf8').encode('shift_jis'))#當sjis輸出utf8的url\n",
    "        key3 = urllib.unquote(key2.decode('shift_jis').encode('utf8'))#utf8的url翻sjis\n",
    "        #網址用\n",
    "        key4 = urllib.quote(key)\n",
    "\n",
    "        #檢查BOM\n",
    "        if '%EF%BB%BF' in urllib.quote(key):\n",
    "            print 'BOM！'\n",
    "\n",
    "        link=\"http://www.daito-i.com/top/show_unit.php\\\n",
    "?mode=search&category=&subcategory=&search_cat=&keyword=\"+key4+\"&sort=&page_num=0\"\n",
    "        \n",
    "        res = requests.get(link)\n",
    "        res.encoding =  res.apparent_encoding#亂碼處理\n",
    "        r= res.text\n",
    "        r=r[r.find(u'<!-- ▼mainContents -->'):r.find(u'<!-- ▲mainContents -->')+len(u'<!-- ▲mainContents -->')]\n",
    "        soup = BeautifulSoup(r ,\"lxml\")#,  parse_only=only_a_tags)\n",
    "        \n",
    "        pn=0\n",
    "        pn = int(soup.select('tr')[1].select('td')[1].text[:soup.select('tr')[1].select('td')[1].text.find(u'件')])\n",
    "        \n",
    "        #updata\n",
    "        if (ucheck == 1) and (os.path.isfile('output/' + key.decode('utf8') + '_doujishiv1.txt')):#更新與欲輸入檔案存在\n",
    "            fupdata = open('output/'+key.decode('utf8') + '_doujishiv1.txt', 'r+')\n",
    "            rf=list(fupdata)\n",
    "            kc=rf[1]\n",
    "            if kc[1:len(key)+1] == key:\n",
    "                oldn=int(rf[2][10:rf[2].find('_')])#建檔時筆數\n",
    "                olddate=rf[2][rf[2].find('_')+1:rf[2].find('_')+11]\n",
    "                olddate=olddate+str(9999)\n",
    "\n",
    "                #更新筆數疊加\n",
    "                for temp in range(rf.count('%\\n')-1):#多一項\n",
    "                    ub=rf.index('%\\n')+2#位移\n",
    "                    rf[rf.index('%\\n')]=''#首項處理\n",
    "                    oldnn=int(rf[ub][7:rf[ub].find('_')])\n",
    "                    oldn=oldn+oldnn\n",
    "                    olddate=rf[ub][rf[ub].find('_')+1:rf[ub].find('_')+11]\n",
    "                    \n",
    "                olddate=olddate.replace('/','')\n",
    "                pn=pn-oldn\n",
    "                print '更新筆數'+str(pn)\n",
    "\n",
    "            if pn==0:#需要更新數為0跳出\n",
    "                fupdata.seek(0, 2)\n",
    "                fupdata.write('!updata\\n!筆數' + str(pn).encode('utf8') +'_'+ strftime(\"%Y/%m/%d\")+'\\n%\\n')\n",
    "                fupdata.close()\n",
    "                return \n",
    "\n",
    "    #資料筆數_是否數字\n",
    "    if pn > 0:\n",
    "        pnn=pn\n",
    "        if int(pn) > pnum:\n",
    "            print 'BIG'\n",
    "\n",
    "        if ucheck == 1:\n",
    "            fupdata.seek(0, 2)\n",
    "            fupdata.write('!updata\\n!筆數' + str(pn).encode('utf8') +'_'+ strftime(\"%Y/%m/%d,%H:%M\")+'->')\n",
    "        else:\n",
    "            fout = open('output/'+key.decode('utf8') + '_daito-iv1.txt', 'w')#寫入模式開檔\n",
    "            fout.write('daito-i\\n')\n",
    "            fout.write('!' + key + '_!'+link+'\\n')\n",
    "            fout.write('!總筆數' + str(pn).encode('utf8') +'_'+ strftime(\"%Y/%m/%d,%H:%M\")+'->')\n",
    "        \n",
    "        print '==daito-i' , pn, '筆'\n",
    "        time.sleep(1)\n",
    "        p = 0#頁\n",
    "        #建空輸出用字典與陣列\n",
    "        dict1={}#新刊\n",
    "        dict2={}#單行本\n",
    "        dict3={}#雜誌\n",
    "        dict4={}#其他#作畫擔任\n",
    "        #dict5={}#其他\n",
    "        dictB={\n",
    "            'dict1':dict1,'dict2':dict2,'dict3':dict3,'dict4':dict4\n",
    "        }\n",
    "        listdict3=[]#雜誌單篇\n",
    "        bdict2 = ''#單行本書目\n",
    "        listdata = []\n",
    "\n",
    "        #資料處理\n",
    "        while (int(pn) - p * pnum) > 0:\n",
    "            print 'page:' + str(p)\n",
    "            \n",
    "            nlink = link[:link.rfind('=')+1]+str(p)\n",
    "            send=[nlink, key, p, pn, pnn, olddate, bdict2]\n",
    "            dictB, listdata, listdict3, pnn, olddate, bdict2 = findbook(dictB, listdata, listdict3, send)#資料處理\n",
    "            p = p + 1\n",
    "            time.sleep(1)\n",
    "\n",
    "        #日期排序\n",
    "        #listdata.sort()\n",
    "\n",
    "        listw=['==new_' + str(len(dictB[\"dict1\"])) +'_新刊\\n',\n",
    "               '==book_' + str(len(dictB[\"dict2\"])) +'_單行本\\n',\n",
    "               '==magazine_' + str(len(dictB[\"dict3\"])) +'_雜誌\\n',\n",
    "               '==other_' + str(len(dictB[\"dict4\"])) +'_他項\\n'\n",
    "              ]\n",
    "        \n",
    "        #紀錄筆數\n",
    "        nb=0\n",
    "        for w in range(len(listw)):\n",
    "            nb= nb+ len(dictB[\"dict\"+str(w+1)])\n",
    "        \n",
    "        #輸出\n",
    "        if ucheck == 1:\n",
    "            fupdata.write(strftime(\"%H:%M\")+'_'+str(nb)+'\\n')\n",
    "            if len(olddate[8:]) > 0:#日期與資料不吻合，可能含舊資料\n",
    "                fupdata.write('!舊資料'+olddate[8:]+'\\n')\n",
    "            for w in range(len(listw)):\n",
    "                if len(dictB[\"dict\"+str(w+1)]) > 0:\n",
    "                    fupdata.write(listw[w])\n",
    "                    save(fupdata , listdata , dictB[\"dict\"+str(w+1)],w+1)\n",
    "            fupdata.write('%\\n')\n",
    "            fupdata.close()\n",
    "            \n",
    "        else:\n",
    "            fout.write(strftime(\"%H:%M\")+'_'+str(nb)+'\\n')\n",
    "            for w in range(len(listw)):\n",
    "                fout.write(listw[w])\n",
    "                save(fout , listdata , dictB[\"dict\"+str(w+1)],w+1)\n",
    "            #單行本與雜誌比對#listdict3_bdict2\n",
    "            out32 = ''\n",
    "            for tmp in listdict3:\n",
    "                if tmp in bdict2:\n",
    "                    tmp='-'+tmp\n",
    "                out32=out32+tmp+'\\n'\n",
    "            \n",
    "            #比對輸出\n",
    "            fout.write('==fd32_' + str(len(listdict3)) +'_比對結果\\n')\n",
    "            fout.write(out32.encode('utf8'))\n",
    "            \n",
    "            fout.write('%\\n')\n",
    "            fout.close()\n",
    "        #sys.exit()################\n",
    "        print 'ok'\n",
    "    elif p:\n",
    "        print '同人'\n",
    "    #\n",
    "    return\n",
    "\n",
    "def log():\n",
    "    '''\n",
    "    log年份\n",
    "    新增模式_動作 筆數 網站 時間 作者 \n",
    "    #'''\n",
    "    return\n",
    "\n",
    "#main(key='八色',ucheck=0)\n",
    "#ほりとも\n",
    "#龍牙翔\n",
    "\n",
    "#已知作者頁面，給定參數建檔。(跳過特殊符號用)\n",
    "#main(key='木星在住',ucheck=2,pn=78,nlink='http://www.doujinshi.org/browse/author/36341/Mokusei-Zaijuu/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lost\n",
      "\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import urllib , requests , sys ,string ,time\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "from time import gmtime, strftime\n",
    "#雜誌類\n",
    "def find_m(blink, key, listdict3):\n",
    "    res = requests.get(blink)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    only_a_tags = SoupStrainer(class_=\"goodTxt\")\n",
    "    soup = BeautifulSoup(res.text ,\"lxml\",  parse_only=only_a_tags)\n",
    "    \n",
    "    bdata = ''\n",
    "    nnum=0\n",
    "    nnum = Q2B(soup.text).encode('utf8').count(key)#作者出現次數\n",
    "    for tm in soup.select('p'):\n",
    "        if (str(tm).count('】') > 4):# and str(tm).count(key):#特徵與作者\n",
    "            tt=Q2B(tm.text).strip().strip('\\n').replace('\\t','').split(u'】')\n",
    "            for t in tt:\n",
    "                if key.decode('utf8') in t[t.find(u'【')+1:]:\n",
    "                    listdict3.append(t[:t.find(u'【')])#比對用疊加\n",
    "                    bdata= bdata+ t[:t.find(u'【')]\n",
    "                    if key.decode('utf8') != t[t.find(u'【')+1:]:\n",
    "                        bdata= bdata+ '['+ t[t.find(u'【')+1:]+ ']'\n",
    "                    bdata= bdata+ '_'\n",
    "            bdata=bdata.strip('_')\n",
    "    return bdata,nnum,listdict3\n",
    "#單行本\n",
    "def find_b(blink, key, bdict2):\n",
    "    #無書目例#http://www.daito-i.com/top/comics/detail.php?code=9784344805408\n",
    "    #有圖http://www.daito-i.com/top/comics/detail.php?code=9784799206096\n",
    "    \n",
    "    res = requests.get(blink)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    only_a_tags = SoupStrainer(class_=\"goodTxt\")\n",
    "    soup = BeautifulSoup(res.text ,\"lxml\",  parse_only=only_a_tags)\n",
    "    \n",
    "    bdata = ''\n",
    "    nnum= 0\n",
    "    nnum = str(soup).count('<br/>')#<br/>次數\n",
    "    for tm in soup.select('p'):\n",
    "        if (str(tm).count('<br/>') > 5):# and str(tm).count(key):\n",
    "            bdata = bdata + '(' + str(str(tm).count('<br/>')) + ')-'#換行次數當單行本話數\n",
    "            bdict2 = bdict2 + tm.get_text('_') + '_'#比對用疊加\n",
    "            bdata = bdata + tm.get_text('\\n-') + '%\\n'\n",
    "        bdata = bdata.strip('\\n')\n",
    "    return bdata,nnum,bdict2\n",
    "\n",
    "key='ほりとも'\n",
    "link='http://www.daito-i.com/top/show_unit.php?\\\n",
    "mode=search&category=&subcategory=&search_cat=&\\\n",
    "keyword=%E9%9B%9B%E5%92%B2%E8%91%89&sort=&page_num=0'\n",
    "#send=[link, key, 0, 30, 30, 1111, 0]\n",
    "#findbook(send)\n",
    "listdict3=[]\n",
    "bdict2 = ''\n",
    "#blink='http://www.daito-i.com/top/comics/detail.php?code=9784799207970'\n",
    "blink='http://www.daito-i.com/top/comics/detail.php?code=9784344805408'\n",
    "#cdata= find_m(blink, key, listdict3)\n",
    "cdata= find_b(blink, key, bdict2)\n",
    "bdata,nnum,bdict2=cdata\n",
    "if len(bdata) < 10:\n",
    "    bdata = 'lost'\n",
    "print bdata\n",
    "for tm in cdata:\n",
    "    print tm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
