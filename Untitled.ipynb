{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すめらぎ琥珀 5 筆資料\n",
      "========\n",
      "<td class=\"list-line list-name\"><a href=\"index.php?p=s&amp;mode=ss&amp;chosha=%E3%81%99%E3%82%81%E3%82%89%E3%81%8E%E3%80%80%E7%90%A5%E7%8F%80&amp;type=title\">すめらぎ　琥珀［著］</a></td>\n",
      "（成）Ｌ．Ｌ．ＣＡＮＤＹ\n",
      "<td class=\"list-line list-name\"><a href=\"index.php?p=s&amp;mode=ss&amp;chosha=%E3%83%A2%E3%82%BF&amp;type=title\">モタ［著］</a><br/><a href=\"index.php?p=s&amp;mode=ss&amp;chosha=%E3%81%99%E3%82%81%E3%82%89%E3%81%8E%E7%90%A5%E7%8F%80&amp;type=title\">すめらぎ琥珀［著］</a></td>\n",
      "君は『ドラゴンズクラウン』を楽しむための３つの巻物を開いた\n",
      "<td class=\"list-line list-name\"><a href=\"index.php?p=s&amp;mode=ss&amp;chosha=%E3%81%99%E3%82%81%E3%82%89%E3%81%8E%E3%80%80%E7%90%A5%E7%8F%80&amp;type=title\">すめらぎ　琥珀［画］</a><br/><a href=\"index.php?p=s&amp;mode=ss&amp;chosha=%E9%AB%98%E5%B2%A1%E3%80%80%E6%9E%9C%E8%BC%AA%EF%BC%88%E3%82%AF%E3%83%AD%E3%82%B9%E3%83%AF%E3%83%BC%E3%82%AF%E3%82%B9%EF%BC%89&amp;type=title\">高岡　果輪（クロスワークス）［シナリオ］</a></td>\n",
      "ランブル\n",
      "<td class=\"list-line list-name\"><a href=\"index.php?p=s&amp;mode=ss&amp;chosha=%E3%81%99%E3%82%81%E3%82%89%E3%81%8E%E3%80%80%E7%90%A5%E7%8F%80&amp;type=title\">すめらぎ　琥珀［著］</a></td>\n",
      "（成）ＭＩＬＫ－ＩＳＭ\n",
      "<td class=\"list-line list-name\"><a href=\"index.php?p=s&amp;mode=ss&amp;chosha=%E3%81%99%E3%82%81%E3%82%89%E3%81%8E%E3%80%80%E7%90%A5%E7%8F%80&amp;type=title\">すめらぎ　琥珀［著］</a></td>\n",
      "（成）Ｓｗｅｅｔ３　Ｒｏｏｍ\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import urllib , requests , sys ,string\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "\n",
    "#爬comiclist\n",
    "#測試用：源五郎\n",
    "#fkey作者來源key.txt\n",
    "#fcomiclist結果key_comiclist.text\n",
    "\n",
    "fkey = open('key.txt', 'r')\n",
    "key = fkey.readline()\n",
    "fkey.close()\n",
    "\n",
    "#檢查BOM\n",
    "if '%EF%BB%BF' in urllib.quote(key):\n",
    "    print 'fuck ms'\n",
    "\n",
    "#key=作者\n",
    "#key = '源五郎'\n",
    "#key2 = urllib.quote(key.decode('utf8').encode('sjis'))\n",
    "#key3 = urllib.unquote(key2.decode('sjis').encode('utf8'))\n",
    "#網址用\n",
    "#key4 = urllib.quote(key)\n",
    "#print key4\n",
    "\n",
    "link = \"http://comiclist.jp/index.php?p=s&mode=ss&keyword=\" + urllib.quote(key) + \"&type=title\"\n",
    "res = requests.get(link)\n",
    "\n",
    "#亂碼處理\n",
    "res.encoding =  res.apparent_encoding\n",
    "\n",
    "only_a_tags = SoupStrainer(id='listArea')\n",
    "soup = BeautifulSoup(res.text ,\"lxml\",  parse_only=only_a_tags)#.prettify()\n",
    "\n",
    "#單行本判斷\n",
    "def findbook(page = 1):\n",
    "    a = 0\n",
    "    #for soup.select('strong')[a]:\n",
    "    for strong in soup.select('strong'):\n",
    "            #print soup.select('strong')[a].text\n",
    "            cname = soup.select('.list-name')[a].text\n",
    "            cbook = soup.select('strong')[a].text\n",
    "            cdata = soup.select('.list-day')[a].text\n",
    "            \n",
    "            #作者處理\n",
    "            #画\n",
    "            #著\n",
    "            #strlit(u'　')\n",
    "            if 'br' in soup.select('.list-name')[a]:\n",
    "                print '<br>'\n",
    "            \n",
    "            print soup.select('.list-name')[a]\n",
    "            #print cname\n",
    "            cname = cname.replace(u'　','')\n",
    "            #ssname = cname.split(u'\\n')\n",
    "            sname = cname.split(u'［')\n",
    "            name = sname[0]\n",
    "            \n",
    "            #書名\n",
    "            \n",
    "            print cbook\n",
    "            \n",
    "            #日期\n",
    "            \n",
    "            #print name.encode('utf8') , urllib.quote(key)\n",
    "            #print urllib.quote(name.encode('utf8'))\n",
    "            \n",
    "            #編碼處理\n",
    "            if key == name.encode('utf8'):\n",
    "                #print key ,  sname[0]\n",
    "                #print soup.select('.list-day')[a].text , soup.select('.list-name')[a].text\n",
    "                fout.write(cbook.encode('utf8') + soup.select('.list-day')[a].text.encode('utf8') + '\\n')\n",
    "            #print key ,  sname[0]\n",
    "            \n",
    "            \n",
    "            \n",
    "            #fout.write(soup.select('strong')[a].text.encode('utf8') + '\\n')\n",
    "            \n",
    "            a = a + 1\n",
    "            \n",
    "\n",
    "#資料筆數\n",
    "#\n",
    "if soup.find_all('b')[1].text > 0:\n",
    "    print key , soup.find_all('b')[1].text , '筆資料\\n========'\n",
    "    \n",
    "    \n",
    "    fout = open(key.decode('utf8') + '_comiclist.txt', 'w')\n",
    "    fout.write('out\\n')\n",
    "    findbook()\n",
    "    fout.close()\n",
    "#print soup.select('.search_page_link_info')[1].text\n",
    "#print soup.select('.search_page_link_info')[1]\n",
    "\n",
    "#爬蟲重點內容\n",
    "#print soup.select('#listBOX-search')[0].text\n",
    "\n",
    "#print soup.select('td[class^=\"list-line\"]')\n",
    "#print res.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
