{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "BIG\n",
      "エレクトさわる 59 num\n",
      "========v1\n",
      "page:0\n",
      "30 .\n",
      "page:1\n",
      "29 .\n",
      "ok\n",
      "3 .. 2 .. 1 ..\n",
      "Press Any Key To Exit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import urllib , requests , sys ,string ,time\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "from time import gmtime, strftime\n",
    "\n",
    "#toranoana\n",
    "#fkey作者來源key.txt\n",
    "#fcomiclist結果key_toranoana.text\n",
    "\n",
    "#輸出格式：\n",
    "#toranoana\n",
    "#!作者\n",
    "#!總筆數\n",
    "#==類別_數量_中文敘述\n",
    "#[同人團_作者群][原作][同人場cXX]同人作品\n",
    "#參考網址\n",
    "\n",
    "#頁顯示數量\n",
    "pnum = 30\n",
    "mlink = 'http://www.toranoana.jp/'\n",
    "\n",
    "fkey = open('key.txt', 'r')\n",
    "key = fkey.readline()#key=作者\n",
    "fkey.close()\n",
    "\n",
    "#key=作者\n",
    "key2 = urllib.quote(key.decode('utf8').encode('shift_jis'))#當sjis輸出utf8的url\n",
    "key3 = urllib.unquote(key2.decode('shift_jis').encode('utf8'))#utf8的url翻sjis\n",
    "#網址用\n",
    "key4 = urllib.quote(key)\n",
    "\n",
    "#檢查BOM\n",
    "if '%EF%BB%BF' in urllib.quote(key):\n",
    "    print 'fuck ms'\n",
    "\n",
    "'''\n",
    "#res = requests.post(\"http://www.toranoana.jp/cgi-bin/R2/d_search.cgi\", data = adict)\n",
    "\n",
    "網址樣本\n",
    "http://www.toranoana.jp/cgi-bin/R2/d_search.cgi\n",
    "?item_kind=0401\n",
    "&stk=1\n",
    "&obj=0\n",
    "&nam=\n",
    "&mak=\n",
    "&act=%82%cd%82%e9%82%e9%82%f1#作者\n",
    "&adl=0\n",
    "&img=0#圖顯示0不顯示，1顯示\n",
    "&dys=\n",
    "&dms=01\n",
    "&dye=\n",
    "&dme=01\n",
    "&bl_fg=0\n",
    "&ps=1#頁數控制，31 61\n",
    "&itc=\n",
    "&ikb=\n",
    "&gnr=\n",
    "&mch=\n",
    "&com=\n",
    "\n",
    "'''\n",
    "\n",
    "link = \"http://www.toranoana.jp/cgi-bin/R2/d_search.cgi?item_kind=0401&stk=1&obj=0&nam=&mak=&act=\" + key2 + \"&adl=0&img=0&dys=&dms=01&dye=&dme=01&ps=1&bl_fg=0&itc=&ikb=&gnr=&mch=&com=\"\n",
    "cookies = {'_tcuid':'201602230349005234',\n",
    "               '_tcuid_updated_at':'1456170540395',\n",
    "               '_tcsid':'201602230349001329',\n",
    "               '_tcsid_updated_at':'1456170540395',\n",
    "               '_ga':'GA1.2.1089385032.1456170540',\n",
    "               'afg':'0'\n",
    "}#作品頁面年齡驗證\n",
    "\n",
    "res = requests.get(link)\n",
    "res.encoding =  res.apparent_encoding#亂碼處理\n",
    "r= res.text\n",
    "r=r[r.find(u'<!-- MAIN AREA -->'):r.find(u'<!-- /MAIN AREA -->')+len(u'<!-- /MAIN AREA -->')]#搜尋結果擷取\n",
    "#r=r[r.find(u'<!-- MAIN AREA -->'):r.rfind(u'</table>')+len(u'</table>')]#搜尋結果擷取\n",
    "#print r\n",
    "\n",
    "only_a_tags = SoupStrainer(\"table\",class_=\"f_tbl_9cf\",cellspacing=\"1\")#縮小檢索範圍\n",
    "soup = BeautifulSoup(r,\"html.parser\",  parse_only=only_a_tags)\n",
    "\n",
    "def next(page = 2):\n",
    "    #page=int(page)\n",
    "    ps=page*pnum+1\n",
    "    link = \"http://www.toranoana.jp/cgi-bin/R2/d_search.cgi?item_kind=0401&stk=1&obj=0&nam=&mak=&act=\" + key2 +     \"&adl=0&img=0&dys=&dms=01&dye=&dme=01&ps=\"+str(ps)+\"&bl_fg=0&itc=&ikb=&gnr=&mch=&com=\"\n",
    "    \n",
    "    res = requests.get(link)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    r= res.text\n",
    "    r=r[r.find(u'<!-- MAIN AREA -->'):r.find(u'<!-- /MAIN AREA -->')+len(u'<!-- /MAIN AREA -->')]#搜尋結果擷取\n",
    "    \n",
    "    only_a_tags = SoupStrainer(\"tr\", class_=\"TBLdtil\")#縮小處理範圍\n",
    "    #先html.parser解析與縮小範圍，再以字串給lxml\n",
    "    #soup = BeautifulSoup(str(BeautifulSoup(res.text,\"html.parser\",  parse_only=only_a_tags)),\"lxml\")\n",
    "    soup = BeautifulSoup(r,\"lxml\",  parse_only=only_a_tags)\n",
    "    \n",
    "    return soup\n",
    "\n",
    "#全轉半\n",
    "def Q2B(ustring):\n",
    "    fs=u'０１２３４５６７８９ＱｑＷｗＥｅＲｒＴｔＹｙＵｕＩｉＯｏＰｐＡａＳｓＤｄＦｆＧｇＨｈＪｊＫｋＬｌＺｚＸｘＣｃＶｖＢｂＮｎＭｍ'\n",
    "    hs=u'0123456789QqWwEeRrTtYyUuIiOoPpAaSsDdFfGgHhJjKkLlZzXxCcVvBbNnMm'\n",
    "    rstr = ''\n",
    "    for tm in ustring:\n",
    "        if fs.find(tm)+1:\n",
    "            tm = hs[fs.find(tm)]\n",
    "        rstr = rstr + tm\n",
    "    ustring = rstr\n",
    "    ustring=ustring.lower()\n",
    "    return ustring\n",
    "#半轉全\n",
    "def B2Q(ustring):\n",
    "    fs=u'０１２３４５６７８９ＱｑＷｗＥｅＲｒＴｔＹｙＵｕＩｉＯｏＰｐＡａＳｓＤｄＦｆＧｇＨｈＪｊＫｋＬｌＺｚＸｘＣｃＶｖＢｂＮｎＭｍ'\n",
    "    hs=u'0123456789QqWwEeRrTtYyUuIiOoPpAaSsDdFfGgHhJjKkLlZzXxCcVvBbNnMm'\n",
    "    rstr = ''\n",
    "    ustring=ustring.lower()\n",
    "    for tm in ustring:\n",
    "        if hs.find(tm)+1:\n",
    "            tm = fs[hs.find(tm)]\n",
    "        rstr = rstr + tm\n",
    "    ustring = rstr\n",
    "    return ustring\n",
    "\n",
    "#資料儲存\n",
    "def save(sdict , check=0):\n",
    "    for temp in listdata:\n",
    "        if sdict.get(temp):\n",
    "            fout.write(sdict[temp].encode('utf8')  + '\\n')\n",
    "    #return\n",
    "\n",
    "#作品頁面\n",
    "def finddata(dlink):\n",
    "    res = requests.get(dlink,cookies=cookies)\n",
    "    res.encoding =  res.apparent_encoding#亂碼處理\n",
    "    r= res.text\n",
    "    r=r[r.find(u'<td class=\\\"Main\\\">'):r.find(u'<!--フッターここまで-->')+len(u'<!--フッターここまで-->')]+u'\\n</td>'#搜尋結果擷取\n",
    "    \n",
    "    only_a_tags = SoupStrainer(\"table\", summary=\"Details\")#縮小檢索範圍\n",
    "    sou=BeautifulSoup(r,\"lxml\",  parse_only=only_a_tags)\n",
    "    \n",
    "    dname=sou.select('.DetailData_L')[2].text#作者\n",
    "    draw=sou.select('.DetailData_L')[3].text#同人原作\n",
    "    dtype=sou.select('.DetailData_R')[0].text#類型\n",
    "    ddate=sou.select('.DetailData_R')[1].text#日期\n",
    "    \n",
    "    dname=Q2B(dname.strip().strip(u'\\n').replace('\\n',' ').replace('\\t',''))\n",
    "    draw=draw.strip().strip(u'\\n').replace('\\n','').replace('\\t','')\n",
    "    #print dname,draw,dtype,ddate\n",
    "    return dname,draw,dtype,ddate\n",
    "\n",
    "#資料處理\n",
    "def findbook(soup , page = 1):\n",
    "    global bl\n",
    "    a =0\n",
    "    check = 0\n",
    "    for tb in soup.select('.TBLdtil'):\n",
    "        a=a+1\n",
    "        print '\\r',a,\n",
    "        '''\n",
    "        if a>5:\n",
    "            break\n",
    "        #'''\n",
    "        clink= tb.select('a')[0].get('href')[1:]#連結\n",
    "        cbook=tb.select('.noi_c2')[0].text#作品名\n",
    "        cbl=tb.select('.noi_c5')[0].text#作品取向_判斷BL作\n",
    "        cclub=tb.select('.noi_c3')[0].text#社團\n",
    "        #print clink,cname,cbl\n",
    "        #print a,#cclub,\n",
    "        \n",
    "        #網址\n",
    "        blink = ''\n",
    "        blink=mlink+clink\n",
    "        \n",
    "        if (u'株式会社虎の穴' in cclub) or (u'【とらのあな' in cbook):\n",
    "            continue#跳過虎穴出品\n",
    "        else:\n",
    "            cname,craw,ctype,cdate=finddata(blink)\n",
    "            if (key.decode('utf8') in cname) and ((u'同人誌' in ctype) or (u'同人CG集' in ctype)):\n",
    "                if key.decode('utf8') ==cname:\n",
    "                    check=1#單作者\n",
    "                else:\n",
    "                    check=2#多作者\n",
    "            else:\n",
    "                continue#跳過非目標作者\n",
    "        \n",
    "        #日期處理\n",
    "        #無日期sample_http://www.toranoana.jp/mailorder/article/04/0000/01/66/040000016646.html\n",
    "        if len(cdate) < 3:#無日期\n",
    "            cdate = '0000/00/00'#填入日期\n",
    "            check = 4#新作\n",
    "        date = cdate\n",
    "        while listdata.count(date):#重複日期判斷\n",
    "            date = date[:8] + str(int(date[8:]) + 1).rjust(2,'0')#日期+1_十位數填0\n",
    "        listdata.append(date)\n",
    "        \n",
    "        #bl\n",
    "        if u'女性向' in cbl:\n",
    "            bl=bl+1\n",
    "        \n",
    "        book=cbook.strip().strip(u'\\n')\n",
    "        club=cclub.strip().strip(u'\\n').replace('\\n','')\n",
    "        name=cname\n",
    "        raw=craw\n",
    "        dtype=ctype\n",
    "        #print key,book,name,club,raw,date,dtype,bl\n",
    "        \n",
    "        #寫入dict\n",
    "        #單作者參考格式_[To Heart 2][c69]年末年始ドリームジャンボ★宝くじ\n",
    "        #多作者參考格式_[PINK+Petite*Cerisier][To Heart 2][c69]年末年始ドリームジャンボ★宝くじ\n",
    "        book=u'['+raw+u']'+u'[-]'+book#[原作][同人場cXX]同人作品\n",
    "        if check==1:\n",
    "            book=club+'_'+book\n",
    "            dict1.setdefault(date,book)\n",
    "        else:\n",
    "            book=u'['+club+'_'+name+u']'+book+'\\n!'+blink\n",
    "            dict2.setdefault(date,book)\n",
    "        \n",
    "        #continue\n",
    "    print '.'\n",
    "    #print '========'\n",
    "    #return\n",
    "\n",
    "########\n",
    "\n",
    "key=key.lower()\n",
    "pn=0\n",
    "if soup.select('span'):\n",
    "    pn=int(soup.select('span')[2].text[:soup.select('span')[2].text.find(u'件')])#資料筆數\n",
    "\n",
    "'''\n",
    "成年向け同人誌 -\n",
    "全年齢対象同人誌 -\n",
    "同人CG\n",
    "#sample_http://www.toranoana.jp/mailorder/article/04/0010/13/34/040010133499.html\n",
    "- 同人ソフト -軟體\n",
    "- 同人音楽作品 -CD\n",
    "- 同人グッズ -周邊\n",
    "#'''\n",
    "\n",
    "#資料筆數_是否數字\n",
    "if pn>0:\n",
    "    print 'ok'\n",
    "    #print soup.find_all('b')\n",
    "    \n",
    "    if pn > pnum:\n",
    "        print 'BIG'\n",
    "    \n",
    "    fout = open('output/'+key.decode('utf8') + '_toranoanav1.txt', 'w')#寫入模式開檔\n",
    "    fout.write('toranoana\\n')#toranoana\n",
    "    print key , pn , 'num\\n========v1'\n",
    "    time.sleep(1)\n",
    "    fout.write('!' + key + '\\n!總筆數' + str(pn).encode('utf8') +'_'+ strftime(\"%Y/%m/%d,%H:%M\")+'->')\n",
    "    \n",
    "    p = 0#頁\n",
    "    #建空輸出用字典與陣列\n",
    "    dict1={}#單作者\n",
    "    dict2={}#多作者\n",
    "    listdata = []\n",
    "    bl=0#bl作品數\n",
    "    \n",
    "    #資料處理\n",
    "    while (int(pn) - p * pnum) > 0:\n",
    "        \n",
    "        print 'page:' + str(p)\n",
    "        soup = next(p)#頁\n",
    "        #print soup.select('.TBLdtil')[2]\n",
    "        findbook(soup)#資料處理\n",
    "        time.sleep(1)\n",
    "        p = p + 1\n",
    "    \n",
    "    #日期排序\n",
    "    listdata.sort()\n",
    "    \n",
    "    fout.write(strftime(\"%H:%M\")+'\\n')\n",
    "    #fout.write('!BL數'+str(bl).encode('utf8')+'\\n')\n",
    "    if bl > 0:\n",
    "        fout.write('!BL數'+str(bl).encode('utf8')+'\\n')\n",
    "    temp = ''\n",
    "    #dict2_多作者\n",
    "    fout.write('==anime_' + str(len(dict2)) +'_同人多作者\\n')\n",
    "    save(dict2)\n",
    "    #dict1_單作者\n",
    "    fout.write('==book_' + str(len(dict1)) +'_同人單作者\\n')\n",
    "    save(dict1)\n",
    "    \n",
    "    #sys.exit()################\n",
    "    fout.close()\n",
    "    print 'ok'\n",
    "elif pn:\n",
    "    print 'No Date'\n",
    "\n",
    "#結束讀秒\n",
    "x=3\n",
    "while x!=0:\n",
    "    print x,'..',\n",
    "    x=x-1\n",
    "    time.sleep(1)\n",
    "raw_input(\"\\nPress Any Key To Exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ヤサカニ・アンエレクトさわる2号 他 \n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import urllib , requests , sys ,string ,time\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "from time import gmtime, strftime\n",
    "fkey = open('key.txt', 'r')\n",
    "key = fkey.readline()#key=作者\n",
    "fkey.close()\n",
    "key=key.lower()\n",
    "mlink = 'http://www.toranoana.jp/'\n",
    "c='''<td class=\"DetailData_L\">\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t<a href=\"/mailorder/cot/author/81/a5e4a5b5a5aba5cba1a6a5a2a5f3_01.html\">ヤサカニ・アン</a> \n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t<a href=\"/mailorder/cot/author/14/a5a8a5eca5afa5c8a4b5a4efa4eb_01.html\">エレクトさわる</a> \n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t<a href=\"/mailorder/cot/author/52/32b9e6_01.html\">2号</a> \n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t他 \n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t</td>\n",
    "'''\n",
    "\n",
    "#link='http://www.toranoana.jp/mailorder/article/04/0030/32/21/040030322168.html'\n",
    "link='http://www.toranoana.jp/mailorder/article/04/0000/01/66/040000016646.html'\n",
    "payload = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36',\n",
    "    'Cookie':'_tcuid=201602230335498253;_tcuid_updated_at=1456169749024;_tcsid=201602230335490499; _tcsid_updated_at=1456169818666; afg=0; _ga=GA1.2.1555831105.1456169749',\n",
    "    'Referer:http':'//www.toranoana.jp/mailorder/article/04/0030/32/21/040030322168.html'\n",
    "}\n",
    "cookies = {'_tcuid':'201602230349005234',\n",
    "               '_tcuid_updated_at':'1456170540395',\n",
    "               '_tcsid':'201602230349001329',\n",
    "               '_tcsid_updated_at':'1456170540395',\n",
    "               '_ga':'GA1.2.1089385032.1456170540',\n",
    "               'afg':'0'\n",
    "}#'''\n",
    "#cookies = dict(cookies_are='working')\n",
    "#Cookie:_tcuid=201602230335498253; _tcuid_updated_at=1456169749024; _tcsid=201602230335490499; _tcsid_updated_at=1456169818666; afg=0; _ga=GA1.2.1555831105.1456169749\n",
    "#res=requests.session()\n",
    "#re = res.get(link,data=payload)\n",
    "'''\n",
    "res = requests.get(link,cookies=cookies)\n",
    "res.encoding =  res.apparent_encoding#亂碼處理\n",
    "r= res.text\n",
    "\n",
    "r=r[r.find(u'<td class=\\\"Main\\\">'):r.find(u'<!--フッターここまで-->')+len(u'<!--フッターここまで-->')]+u'\\n</td>'#搜尋結果擷取\n",
    "\n",
    "only_a_tags = SoupStrainer(\"table\", summary=\"Details\")#縮小檢索範圍\n",
    "#class=\"Main\"\n",
    "#soup=BeautifulSoup(r,\"html.parser\")#,  parse_only=only_a_tags)\n",
    "soup=BeautifulSoup(r,\"lxml\",  parse_only=only_a_tags)\n",
    "#'''\n",
    "soup=BeautifulSoup(c,\"lxml\")#,  parse_only=only_a_tags)\n",
    "\n",
    "#print len(res.text),len(str(soup)),len(str(sou))\n",
    "#print soup\n",
    "print soup.text.replace('\\t','').replace('\\n','')\n",
    "'''\n",
    "print len(soup.select('.DetailData_L')),soup.select('.DetailData_L')[0]\n",
    "print len(soup.select('.DetailData_R')),soup.select('.DetailData_R')[0]\n",
    "\n",
    "dname=soup.select('.DetailData_L')[2].text\n",
    "draw=soup.select('.DetailData_L')[3].text\n",
    "dtype=soup.select('.DetailData_R')[0].text\n",
    "ddate=soup.select('.DetailData_R')[1].text\n",
    "#dtype='cg'\n",
    "#draw='1 2'\n",
    "#[PINK+Petite*Cerisier][To Heart 2][c69]年末年始ドリームジャンボ★宝くじ\n",
    "dname=dname.strip().strip(u'\\n')\n",
    "draw=draw.strip().strip(u'\\n')\n",
    "#key='黒犬獣'\n",
    "print type(key.decode('utf8'))\n",
    "check=0\n",
    "if (key.decode('utf8') in dname) and ((u'同人誌' in dtype) or (u'同人CG集' in dtype)):\n",
    "    if key.decode('utf8') ==dname:\n",
    "        check=1\n",
    "        print '1'\n",
    "    else:\n",
    "        check=2\n",
    "    print key,dname,draw,ddate,len(ddate)\n",
    "\n",
    "if len(ddate) < 8:#無日期\n",
    "    ddate = '0000/00/00'#填入日期\n",
    "    #check = 4#新作\n",
    "date = ddate\n",
    "print date[8:]\n",
    "'''\n",
    "\n",
    "'''\n",
    "        #日期處理\n",
    "        #print cdata\n",
    "        cdata = cdata.rstrip()\n",
    "        if len(cdata) < 8:#無日期\n",
    "            cdata = '0000/00/00'#填入日期\n",
    "            check = 4#新作\n",
    "        data = cdata\n",
    "        while listdata.count(data):#重複日期判斷\n",
    "            data = data[:8] + str(int(data[8:]) + 1).rjust(2,'0')#日期+1_十位數填0\n",
    "        listdata.append(data)\n",
    "\n",
    "#'''\n",
    "b=0\n",
    "for a in range(10):\n",
    "    print b\n",
    "else:\n",
    "    b=b+1\n",
    "#print soup.select('table')[3]\n",
    "#print re.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
