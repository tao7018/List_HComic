{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIG\n",
      "==dlsite 44 筆\n",
      "page:1\n",
      "30 30\n",
      "43 check 2\n",
      "2 木星在住 20141212\n",
      "http://www.dlsite.com/books/work/=/product_id/BJ048285.html\n",
      "42 check 2\n",
      "3 あり_よしじまあたる_2号_木星在住_あさぎ龍_RED-RUM 20141213\n",
      "http://www.dlsite.com/books/work/=/product_id/BJ048283.html\n",
      "41 check 2\n",
      "check 7\n",
      "1 !木星在住\n",
      "8 株式会社虎の穴 20141102\n",
      "http://www.dlsite.com/maniax/work/=/product_id/RJ133093.html\n",
      ".\n",
      "page:2\n",
      "14 14\n",
      "40 check 2\n",
      "check 7\n",
      "1 !木星在住dojin\n",
      "8 木星在住DOJIN 20130128\n",
      "http://www.dlsite.com/maniax/work/=/product_id/RJ109912.html\n",
      "39 check 2\n",
      "check 7\n",
      "1 !木星在住dojin\n",
      "8 木星在住DOJIN 20130127\n",
      "http://www.dlsite.com/maniax/work/=/product_id/RJ109910.html\n",
      "38 check 2\n",
      "check 7\n",
      "1 !木星在住dojin\n",
      "8 木星在住DOJIN 20121203\n",
      "http://www.dlsite.com/maniax/work/=/product_id/RJ106733.html\n",
      ".\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import urllib , requests , sys , string   ,time , os\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "from time import gmtime , strftime\n",
    "#dlsite\n",
    "#fkey作者來源key.txt\n",
    "#fcomiclist結果key_dlsite.text\n",
    "\n",
    "#輸出格式：\n",
    "#dlsite\n",
    "#!作者\n",
    "#!總筆數\n",
    "#==類別_數量_中文敘述\n",
    "#類別_品名\n",
    "#網址\n",
    "'''\n",
    "#木星在住DOJIN\n",
    "<span class=\"icon_GAM\" title=\"同人ゲーム\">同人ゲーム</span>\n",
    "<span class=\"icon_SOF\" title=\"同人ソフト\">同人ソフト</span>\n",
    "<span class=\"icon_DOH\" title=\"同人誌\">同人誌</span>\n",
    "GAM,SOF,DOH\n",
    "\n",
    "<span class=\"icon_EVT\" title=\"コミックマーケット86\">コミックマーケット86</span>\n",
    "C89\n",
    "\n",
    "<span class=\"icon_ADL\" title=\"18禁\">18禁</span>\n",
    "\n",
    "####\n",
    "listtype=[[],[MDC,SCM,MNG],[],[IN2,INV,NR2,NRE,ET3,ET4,ACN,QIZ,ADV,RPG,TBL,DNV,SLN,TYP,STG,PZL,ETC],\n",
    "[MOV],[SOU,MUS,ICG,IST,GSH],[GAM,SOF,DOH],[],[]]\n",
    "\n",
    "2_MDC,SCM,MNG\n",
    "\n",
    "4_IN2,INV,NR2,NRE,ET3,ET4,ACN,QIZ,ADV,RPG,TBL,DNV,SLN,TYP,STG,PZL,ETC\n",
    "5_MOV\n",
    "\n",
    "6_SOU,MUS,ICG,IST,GSH\n",
    "7_GAM,SOF,DOH\n",
    "\n",
    "\n",
    "#'''\n",
    "\n",
    "#全轉半_含轉小寫\n",
    "def Q2B(ustring):\n",
    "    fs=u'０１２３４５６７８９ＱｑＷｗＥｅＲｒＴｔＹｙＵｕＩｉＯｏＰｐ\\\n",
    "ＡａＳｓＤｄＦｆＧｇＨｈＪｊＫｋＬｌＺｚＸｘＣｃＶｖＢｂＮｎＭｍ'\n",
    "    hs=u'0123456789QqWwEeRrTtYyUuIiOoPpAaSsDdFfGgHhJjKkLlZzXxCcVvBbNnMm'\n",
    "    rstr = ''\n",
    "    for tm in ustring:\n",
    "        if fs.find(tm)+1:\n",
    "            tm = hs[fs.find(tm)]\n",
    "        rstr = rstr + tm\n",
    "    ustring = rstr\n",
    "    ustring=ustring.lower()\n",
    "    return ustring\n",
    "\n",
    "#資料儲存\n",
    "def save(fout , listdata , sdict , check=0):\n",
    "    for tep in listdata:\n",
    "        if sdict.get(tep):\n",
    "            fout.write(sdict[tep]  + '\\n')\n",
    "    #return\n",
    "\n",
    "def finddata(key, blink, check):\n",
    "    #作者頁範例_http://www.dlsite.com/pro/work/=/product_id/VJ008602.html\n",
    "    res = requests.get(blink)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    rr=res.text\n",
    "    rr=rr[rr.rfind('<div id=\\\"work_header\\\"'):rr.rfind('<!-- /work_story -->')]\n",
    "    sou=BeautifulSoup(rr,\"lxml\")\n",
    "    \n",
    "    bdata=''\n",
    "    #資訊欄位\n",
    "    n1 = Q2B(sou.select('#work_right_inner')[0].text).encode('utf8').count(key)#作者出現次數\n",
    "    if n1 > 0:\n",
    "        tm=Q2B(sou.select('#work_right_inner')[0].text)#.replace('\\r','')\n",
    "        for temp in range(n1):\n",
    "            t1=tm.rfind(u'\\n',0,tm.find(key.decode('utf8')))\n",
    "            t2=tm.find(u'\\n',tm.find(key.decode('utf8')))\n",
    "            bdata=bdata+'!'+tm[t1 : t2].strip(u' \\n\\r\\t')\n",
    "            tm=tm[t2:]\n",
    "    #內容欄位\n",
    "    n2 = Q2B(sou.select('.work_article.work_story')[0].text).encode('utf8').count(key)#作者出現次數\n",
    "    if n2 > 0:\n",
    "        tm=Q2B(sou.select('.work_article.work_story')[0].text).replace('\\r','')\n",
    "        for temp in range(n2):\n",
    "            t1=tm.rfind(u'\\n',0,tm.find(key.decode('utf8')))\n",
    "            t2=tm.find(u'\\n',tm.find(key.decode('utf8')))\n",
    "            bdata=bdata+'!'+tm[t1 : t2].strip(u' \\n\\r\\t')\n",
    "            tm=tm[tm.find(key.decode('utf8'))+len(key.decode('utf8')):]\n",
    "    nnum=n1+n2\n",
    "    \n",
    "    return nnum,bdata\n",
    "\n",
    "\n",
    "#資料處理\n",
    "def findbook(dictB, listdata, receive):\n",
    "    link, key, p, pn, pnn, olddate=receive\n",
    "    mlink = 'http://www.dlsite.com/books/'\n",
    "    if len(link)<5:\n",
    "        return dictB, listdata, pnn, olddate\n",
    "    \n",
    "    res = requests.get(link)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    r= res.text\n",
    "    rt=u'<table class=\\\"work_1col_table\\\" cellspacing=\\\"0\\\">'\n",
    "    r=r[r.find(rt)+len(rt):r.find(u'<script type=\\'text/javascript\\'>')]\n",
    "    r=r[:r.rfind(u'</table>')]\n",
    "    \n",
    "    bn=r.count('work_1col_thumb')#頁作品數\n",
    "    doc=r.split('<tr>\\n<td colspan=\\\"3\\\">\\n<hr class=\\\"work_border\\\" />\\n</td>\\n</tr>')\n",
    "    #doc.pop()#多餘項\n",
    "    #print bn,len(soup.select('tr')),len(soup.select('td'))\n",
    "    \n",
    "    print len(doc),bn\n",
    "    \n",
    "    listtype = [[], [], ['MDC','SCM','MNG'], [],\n",
    "                ['IN2','INV','NR2','NRE','ACN','QIZ','ADV','RPG','TBL','DNV','SLN','TYP','STG','PZL','ETC'],\n",
    "                ['MOV'], ['SOU','MUS','ICG','IST','GSH'], ['ET3','ET4','GAM','SOF','DOH'], [], []]\n",
    "    #<span class=\"icon_ADL\" title=\"18禁\">18禁</span>\n",
    "    \n",
    "    a =0\n",
    "    for tm in doc[:3]:\n",
    "        if pnn==0:\n",
    "            return dictB,listdata,oname,mindate,pnn,olddate\n",
    "        pnn=pnn-1\n",
    "        a=a+1\n",
    "        print '\\r',pnn,\n",
    "        \n",
    "        sou = BeautifulSoup(tm,\"lxml\")\n",
    "        \n",
    "        ctype = sou.find(class_='work_genre')\n",
    "        cbook = sou.select('.work_name')[0].text.strip(' \\n')\n",
    "        cdate = sou.select('.sales_date')[0].text.strip(' \\n')\n",
    "        cname = sou.select('.maker_name')[0].text.strip(' \\n')\n",
    "        check = 0\n",
    "        \n",
    "        blink = ''\n",
    "        blink = sou.select('.work_name')[0].select('a')[0].get('href')\n",
    "        \n",
    "        \n",
    "        #&nbsp;_\\xa0\n",
    "        #print repr(cname)\n",
    "        \n",
    "        #類型處理\n",
    "        for t in listtype:\n",
    "            for tt in ctype.select('span'):\n",
    "                if tt.get('class')[0][5:] in t:\n",
    "                    check=listtype.index(t)\n",
    "                    print 'check',check\n",
    "        if check==0:\n",
    "            continue\n",
    "        \n",
    "        #作者處理\n",
    "        if u'\\xa0/\\xa0' in cname:#出版商\n",
    "            cname=cname[:cname.rfind(u'\\xa0/\\xa0')]\n",
    "        nname=cname.split(u'\\xa0')\n",
    "        if (len(nname) > 1) and (check==2):#多人漫\n",
    "            check=3\n",
    "        \n",
    "        bname=''\n",
    "        c=0\n",
    "        for tt in nname:\n",
    "            if key.decode('utf8') == tt:\n",
    "                c=1\n",
    "                #print 'find'\n",
    "            #elif (key.decode('utf8') in tt) and (c==0):\n",
    "                #c=2\n",
    "                #print 'find#'\n",
    "            bname=bname+tt+'_'\n",
    "        bname=bname.strip('_')\n",
    "        if c==0:# and (check==2 or check==3 or check==7)\n",
    "            check=8\n",
    "            #print 'X'\n",
    "            nnum,bdata = finddata(key, blink, check)\n",
    "            print nnum,bdata\n",
    "            #=finddata(blink)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        #予告開始日 : \t2015年04月24日\n",
    "        #販売日: 2015年08月21日\n",
    "        if u'予告開始日' in cdate:\n",
    "            cdate=cdate[7:].replace(u'年','').replace(u'月','').replace(u'日','')\n",
    "            check=1\n",
    "        else:\n",
    "            cdate=cdate[5:].replace(u'年','').replace(u'月','').replace(u'日','')'''\n",
    "        \n",
    "        #日期處理\n",
    "        cdate=cdate[5:].replace(u'年','').replace(u'月','').replace(u'日','')\n",
    "        if len(cdate) < 4:#無日期\n",
    "            cdate = '00000000'#填入日期\n",
    "        date = cdate\n",
    "        while listdata.count(date):#重複日期判斷\n",
    "            date = date[:-2] + str(int(date[-2:]) + 1).rjust(2,'0')#日期+1_十位數填0\n",
    "        listdata.append(date)\n",
    "        \n",
    "        #print ctype,'###'#cbook,cdate\n",
    "        \n",
    "        print check,bname,date\n",
    "        print blink\n",
    "        continue\n",
    "        \n",
    "        \n",
    "        #作品處理\n",
    "        #日期_品名\n",
    "        #類型_nnum1_bdate1_nnum2_bdate2\n",
    "        cfind=bfind(blink)\n",
    "        #print '########catch:',len(cfind)#,cfind[:]\n",
    "        ctype=cfind[0]\n",
    "        cnum1=str(cfind[1]).decode('utf8')\n",
    "        cdate1=cfind[2]\n",
    "        cnum2=str(cfind[3]).decode('utf8')\n",
    "        cdate2=cfind[4]\n",
    "        check=cfind[5]\n",
    "        \n",
    "        \n",
    "        #寫入dict\n",
    "        #參考1參考2，無筆數則不紀錄。\n",
    "        if check == 1:#新\n",
    "            #日期_類型_品名_\n",
    "            #!參考1!連結\n",
    "            book=data+'_'+dtype+'_'+book+'_\\n!'+cnum1+'!'+blink\n",
    "            dict1.setdefault(data,book)\n",
    "        elif check == 2:#漫單\n",
    "            #類型_品名_作者資料1_\n",
    "            book=dtype+'_'+book+'_'+cdate1+'_'\n",
    "            dict2.setdefault(data,book)\n",
    "        elif check == 3:#漫多\n",
    "            #類型_品名_作者資料1_\n",
    "            book=dtype+'_'+book+'_'+cdate1+'_'\n",
    "            dict3.setdefault(data,book)\n",
    "        elif check == 4:#漫同人\n",
    "            #類型_品名_作者資料1_\n",
    "            book=dtype+'_'+book+'_'+cdate1+'_'\n",
    "            dict4.setdefault(data,book)\n",
    "        elif check == 5:#它\n",
    "            #類型_品名_作者資料1_\n",
    "            #!參考1!參考2!連結\n",
    "            book=dtype+'_'+book+'_'+cdate1+'_\\n!'+cnum1+'!'+cnum2+'!'+blink\n",
    "            dict5.setdefault(data,book)\n",
    "        elif check == 6:#漫\n",
    "            #類型_品名_\n",
    "            #作者資料2_\n",
    "            #!參考1!參考2!連結\n",
    "            book=dtype+'_'+book+'_\\n'+cdate2+'_\\n!'+cnum1+'!'+cnum2+'!'+blink\n",
    "            dict6.setdefault(data,book)\n",
    "        elif check==7:#它\n",
    "            #類型_品名_\n",
    "            #作者資料2_\n",
    "            #!參考1!參考2!連結\n",
    "            book=dtype+'_'+book+'_\\n'+cdate2+'_\\n!'+cnum1+'!'+cnum2+'!'+blink\n",
    "            dict7.setdefault(data,book)\n",
    "        #print check,'_',book\n",
    "        #'''\n",
    "        \n",
    "        if a==(bn):\n",
    "            break\n",
    "        #continue\n",
    "    print '.'\n",
    "    #print '========'\n",
    "    return dictB, listdata, pnn, olddate\n",
    "\n",
    "########\n",
    "def main(key='',ucheck=0,pn=0,nlink=''):\n",
    "    #ucheck_0建檔_1更新_2直讀\n",
    "    \n",
    "    pnum = 30#頁顯示數量\n",
    "    mlink = 'http://www.dlsite.com/books/'\n",
    "    \n",
    "    olddate=''\n",
    "    if ucheck != 2:\n",
    "        #key=作者\n",
    "        key=key.lower()\n",
    "        key2 = urllib.quote(key.decode('utf8').encode('shift_jis'))#當sjis輸出utf8的url\n",
    "        key3 = urllib.unquote(key2.decode('shift_jis').encode('utf8'))#utf8的url翻sjis\n",
    "        #網址用\n",
    "        key4 = urllib.quote(key)\n",
    "\n",
    "        #檢查BOM\n",
    "        if '%EF%BB%BF' in urllib.quote(key):\n",
    "            print 'BOM！'\n",
    "\n",
    "        link = \"http://www.dlsite.com/maniax/fsr/=/language/jp/\\\n",
    "sex_category%5B0%5D/male/keyword/\"+key4+\"/ana_flg/all/\\\n",
    "order%5B0%5D/release_d/genre_and_or/or/options_and_or/or/per_page/30/show_type/n/page/1\"\n",
    "        \n",
    "        res = requests.get(link)\n",
    "        res.encoding =  res.apparent_encoding#亂碼處理\n",
    "        r= res.text\n",
    "        r=r[r.find(u'<!-- ▼mainContents -->'):r.find(u'<!-- ▲mainContents -->')+len(u'<!-- ▲mainContents -->')]\n",
    "        #soup = BeautifulSoup(r ,\"lxml\")#,  parse_only=only_a_tags)\n",
    "        soup = BeautifulSoup(res.text,\"html.parser\")\n",
    "        \n",
    "        pn=0\n",
    "        if soup.find(class_='page_total'):\n",
    "            pn = int(soup.select('.page_total')[0].strong.text)#資料筆數\n",
    "        \n",
    "        #updata\n",
    "        if (ucheck == 1) and (os.path.isfile('output/' + key.decode('utf8') + '_dlsitev1.txt')):#更新與欲輸入檔案存在\n",
    "            fupdata = open('output/'+key.decode('utf8') + '_dlsitev1.txt', 'r+')\n",
    "            rf=list(fupdata)\n",
    "            kc=rf[1]\n",
    "            if kc[1:len(key)+1] == key:\n",
    "                oldn=int(rf[2][10:rf[2].find('_')])#建檔時筆數\n",
    "                olddate=rf[2][rf[2].find('_')+1:rf[2].find('_')+11]\n",
    "                olddate=olddate+str(9999)\n",
    "\n",
    "                #更新筆數疊加\n",
    "                for temp in range(rf.count('%\\n')-1):#多一項\n",
    "                    ub=rf.index('%\\n')+2#位移\n",
    "                    rf[rf.index('%\\n')]=''#首項處理\n",
    "                    oldnn=int(rf[ub][7:rf[ub].find('_')])\n",
    "                    oldn=oldn+oldnn\n",
    "                    olddate=rf[ub][rf[ub].find('_')+1:rf[ub].find('_')+11]\n",
    "                    \n",
    "                olddate=olddate.replace('/','')\n",
    "                pn=pn-oldn\n",
    "                print '更新筆數'+str(pn)\n",
    "\n",
    "            if pn==0:#需要更新數為0跳出\n",
    "                fupdata.seek(0, 2)\n",
    "                fupdata.write('!updata\\n!筆數' + str(pn).encode('utf8') +'_'+ strftime(\"%Y/%m/%d\")+'\\n%\\n')\n",
    "                fupdata.close()\n",
    "                return \n",
    "\n",
    "    #資料筆數_是否數字\n",
    "    if pn > 0:\n",
    "        pnn=pn\n",
    "        if int(pn) > pnum:\n",
    "            print 'BIG'\n",
    "\n",
    "        if ucheck == 1:\n",
    "            fupdata.seek(0, 2)\n",
    "            fupdata.write('!updata\\n!筆數' + str(pn).encode('utf8') +'_'+ strftime(\"%Y/%m/%d,%H:%M\")+'->')\n",
    "        else:\n",
    "            fout = open('output/'+key.decode('utf8') + '_dlsitev1.txt', 'w')#寫入模式開檔\n",
    "            fout.write('dlsite\\n')\n",
    "            fout.write('!' + key + '_!'+link+'\\n')\n",
    "            fout.write('!總筆數' + str(pn).encode('utf8') +'_'+ strftime(\"%Y/%m/%d,%H:%M\")+'->')\n",
    "        \n",
    "        print '==dlsite' , pn, '筆'\n",
    "        time.sleep(1)\n",
    "        p = 0#頁\n",
    "        #建空輸出用字典與陣列\n",
    "        dict1={}#新\n",
    "        dict2={}#漫單_マンガ\n",
    "        dict3={}#漫多\n",
    "        dict4={}#イラスト＋ノベル_ノベル_ゲーム\n",
    "        dict5={}#動画\n",
    "        dict6={}#其他_音声_音楽_イラスト集_画集\n",
    "        dict7={}#同人_その他\n",
    "        #dict8={}#一般向\n",
    "        dict8={}#它_內容欄\n",
    "        dictB={\n",
    "            'dict1':dict1,'dict2':dict2,'dict3':dict3,'dict4':dict4,\n",
    "            'dict5':dict5,'dict6':dict6,'dict7':dict7,'dict8':dict8\n",
    "            #'dict9':dict9\n",
    "        }\n",
    "        listdata = []\n",
    "        #check=0\n",
    "\n",
    "        #資料處理\n",
    "        while (int(pn) - p * pnum) > 0:\n",
    "            p = p + 1\n",
    "            print 'page:' + str(p)\n",
    "            \n",
    "            nlink = link[:link.rfind('/')+1]+str(p)\n",
    "            send=[nlink, key, p, pn, pnn, olddate]\n",
    "            dictB, listdata, pnn, olddate = findbook(dictB, listdata, send)#資料處理\n",
    "            time.sleep(1)\n",
    "        sys.exit()################\n",
    "\n",
    "        #日期排序\n",
    "        #listdata.sort()\n",
    "        \n",
    "        listw=['==new_' + str(len(dictB[\"dict1\"])) +'_新\\n',\n",
    "               '==book_' + str(len(dictB[\"dict2\"])) +'_漫單\\n',\n",
    "               '==magazine_' + str(len(dictB[\"dict3\"])) +'_漫多\\n',\n",
    "               '==djs_' + str(len(dictB[\"dict4\"])) +'_同人\\n',\n",
    "               '==other_' + str(len(dictB[\"dict5\"])) +'_它\\n',\n",
    "               '==obook_' + str(len(dictB[\"dict6\"])) +'_漫\\n',\n",
    "               '==oother_' + str(len(dictB[\"dict7\"])) +'_它\\n'\n",
    "              ]\n",
    "        \n",
    "        #紀錄筆數\n",
    "        nb=0\n",
    "        for w in range(len(listw)):\n",
    "            nb= nb+ len(dictB[\"dict\"+str(w+1)])\n",
    "        \n",
    "        #輸出\n",
    "        if ucheck == 1:\n",
    "            fupdata.write(strftime(\"%H:%M\")+'_'+str(nb)+'\\n')\n",
    "            if len(olddate[8:]) > 0:#日期與資料不吻合，可能含舊資料\n",
    "                fupdata.write('!舊資料'+olddate[8:]+'\\n')\n",
    "            for w in range(len(listw)):\n",
    "                if len(dictB[\"dict\"+str(w+1)]) > 0:\n",
    "                    fupdata.write(listw[w])\n",
    "                    save(fupdata , listdata , dictB[\"dict\"+str(w+1)],w+1)\n",
    "            fupdata.write('%\\n')\n",
    "            fupdata.close()\n",
    "            \n",
    "        else:\n",
    "            fout.write(strftime(\"%H:%M\")+'_'+str(nb)+'\\n')\n",
    "            for w in range(len(listw)):\n",
    "                fout.write(listw[w])\n",
    "                save(fout , listdata , dictB[\"dict\"+str(w+1)],w+1)\n",
    "            fout.write('%\\n')\n",
    "            fout.close()\n",
    "        \n",
    "        #sys.exit()################\n",
    "        print 'ok'\n",
    "    elif pn:\n",
    "        print 'No Date'\n",
    "    #\n",
    "    return\n",
    "####\n",
    "if __name__ == '__main__':\n",
    "    #main()\n",
    "    main(key='木星在住',ucheck=0)\n",
    "    #main(key='hisasi',ucheck=0)\n",
    "\n",
    "    #已知作者頁面，給定參數建檔。(跳過特殊符號用)\n",
    "    #main(key='木星在住',ucheck=2,pn=78,nlink='http://www.doujinshi.org/browse/author/36341/Mokusei-Zaijuu/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62682 11297 nnum 1\n",
      "!その他 : 原作：『小悪魔カノジョ』（hisasi）\n"
     ]
    }
   ],
   "source": [
    "import urllib , requests , sys ,string ,time\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "\n",
    "def finddata(key, blink, check):\n",
    "    #作者頁範例_http://www.dlsite.com/pro/work/=/product_id/VJ008602.html\n",
    "    res = requests.get(blink)\n",
    "    res.encoding =  res.apparent_encoding\n",
    "    rr=res.text\n",
    "    rr=rr[rr.rfind('<div id=\\\"work_header\\\"'):rr.rfind('<!-- /work_story -->')]\n",
    "    sou=BeautifulSoup(rr,\"lxml\")\n",
    "    \n",
    "    bdata=''\n",
    "    #資訊欄位\n",
    "    n1 = Q2B(sou.select('#work_right_inner')[0].text).encode('utf8').count(key)#作者出現次數\n",
    "    if n1 > 0:\n",
    "        tm=Q2B(sou.select('#work_right_inner')[0].text)#.replace('\\r','')\n",
    "        for temp in range(n1):\n",
    "            #print '#',temp\n",
    "            t1=tm.rfind(u'\\n',0,tm.find(key.decode('utf8')))\n",
    "            t2=tm.find(u'\\n',tm.find(key.decode('utf8')))\n",
    "            bdata=bdata+'!'+tm[t1 : t2].strip(u' \\n\\r\\t')#+u'\\n'\n",
    "            tm=tm[t2:]\n",
    "    #內容欄位\n",
    "    n2 = Q2B(sou.select('.work_article.work_story')[0].text).encode('utf8').count(key)#作者出現次數\n",
    "    if n2 > 0:\n",
    "        tm=Q2B(sou.select('.work_article.work_story')[0].text).replace('\\r','')\n",
    "        for temp in range(n2):\n",
    "            #print '#',temp\n",
    "            t1=tm.rfind(u'\\n',0,tm.find(key.decode('utf8')))\n",
    "            t2=tm.find(u'\\n',tm.find(key.decode('utf8')))\n",
    "            #print t1,t2\n",
    "            bdata=bdata+'!'+tm[t1 : t2].strip(u' \\n\\r\\t')#+u'\\n'\n",
    "            tm=tm[tm.find(key.decode('utf8'))+len(key.decode('utf8')):]\n",
    "    nnum=n1+n2\n",
    "    print len(res.text), len(str(sou)), 'nnum', nnum\n",
    "    print bdata\n",
    "    \n",
    "    #print sou\n",
    "    #return\n",
    "blink='http://www.dlsite.com/maniax/work/=/product_id/RJ133093.html'\n",
    "blink='http://www.dlsite.com/pro/work/=/product_id/VJ008602.html'\n",
    "key='木星在住'\n",
    "key='hisasi'\n",
    "check=2\n",
    "finddata(key,blink,check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
