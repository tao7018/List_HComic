{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "猫島礼 40 筆資料\n",
      "========\n",
      "BIG\n",
      "大塚あきら猫島礼\n",
      "悪夢の招待状\n",
      "卷處理\n",
      "大塚あきら猫島礼\n",
      "悪夢のためいき\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）診察中はお静かに！！\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）ラッシュ！！\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）奴隷天国\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）コスプレ９ｔｏ５\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）ファンタジーカフェ\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）生贄市場\n",
      "卷處理\n",
      "猫島礼他［著\n",
      "女子高生　天誅\n",
      "卷處理\n",
      "猫島礼［著\n",
      "ラブ　ファーマシー\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）ハッピー・クリニック\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）夢先案内猫\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）Ａｆｔｅｒ\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）ＭＡＧＩＣ　ＤＲＡＧＯＮ\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）Ｉ　Ｌｏｖｅ　Ｙｏｕ\n",
      "卷處理\n",
      "猫島礼［著\n",
      "制服ｉｓｍ\n",
      "卷處理\n",
      "猫島礼［著\n",
      "彼女のススメ\n",
      "卷處理\n",
      "猫島礼［著\n",
      "放課後コネクション\n",
      "卷處理\n",
      "猫島礼［著\n",
      "制服しようよ\n",
      "卷處理\n",
      "猫島礼［著\n",
      "お姉様とぷるるん\n",
      "卷處理\n",
      "猫島礼［著\n",
      "癒しま専科\n",
      "卷處理\n",
      "猫島礼［著\n",
      "ポテトクレープ\n",
      "卷處理\n",
      "猫島礼［著\n",
      "診察中はお静かに\n",
      "卷處理\n",
      "猫島礼［著\n",
      "コスプレ９ｔｏ５\n",
      "卷處理\n",
      "猫島礼［著\n",
      "巨乳でガッテン！\n",
      "卷處理\n",
      "猫島礼［著\n",
      "巨乳におまかせ\n",
      "卷處理\n",
      "猫島礼［著\n",
      "お願いシスター\n",
      "卷處理\n",
      "猫島礼［著\n",
      "祓ってプリーズ！\n",
      "卷處理\n",
      "猫島礼［著\n",
      "ファンタジーカフェ\n",
      "卷處理\n",
      "猫島礼［著\n",
      "（成）またたび忍法帖\n",
      "卷處理\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import urllib , requests , sys ,string\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "\n",
    "#爬comiclist\n",
    "#測試用：源五郎\n",
    "#fkey作者來源key.txt\n",
    "#fcomiclist結果key_comiclist.text\n",
    "\n",
    "fkey = open('key.txt', 'r')\n",
    "key = fkey.readline()\n",
    "fkey.close()\n",
    "\n",
    "#檢查BOM\n",
    "if '%EF%BB%BF' in urllib.quote(key):\n",
    "    print 'fuck ms'\n",
    "\n",
    "#key=作者\n",
    "#key = '源五郎'\n",
    "#key2 = urllib.quote(key.decode('utf8').encode('sjis'))\n",
    "#key3 = urllib.unquote(key2.decode('sjis').encode('utf8'))\n",
    "#網址用\n",
    "#key4 = urllib.quote(key)\n",
    "#print key4\n",
    "\n",
    "link = \"http://comiclist.jp/index.php?p=s&mode=ss&keyword=\" + urllib.quote(key) + \"&type=title\"\n",
    "res = requests.get(link)\n",
    "\n",
    "#亂碼處理\n",
    "res.encoding =  res.apparent_encoding\n",
    "#縮小檢索範圍\n",
    "only_a_tags = SoupStrainer(id='listArea')\n",
    "\n",
    "soup = BeautifulSoup(res.text ,\"lxml\",  parse_only=only_a_tags)#.prettify()\n",
    "\n",
    "#資料處理\n",
    "def findbook(page = 1):\n",
    "    a =0\n",
    "    #for soup.select('strong')[a]:\n",
    "    for strong in soup.select('strong'):\n",
    "            #print soup.select('strong')[a].text\n",
    "            cname = soup.select('.list-name')[a].text\n",
    "            cbook = soup.select('strong')[a].text\n",
    "            cdata = soup.select('.list-day')[a].text\n",
    "            \n",
    "            #作者處理\n",
    "            #画_著_無後綴\n",
    "            check = 0\n",
    "            cname = cname.replace(u'　','')\n",
    "            #while對split切不出不視為陣列？\n",
    "            if u'］' not in cname:\n",
    "                cname = cname + u'］'\n",
    "            sname = cname.split(u'］')\n",
    "            b = 0\n",
    "            print sname[b]\n",
    "            name = ''\n",
    "            \n",
    "            #'''\n",
    "            while len(sname[b]) > 0:\n",
    "            #while sname[b]:\n",
    "            #for sname[b]:\n",
    "                #s_name = sname[b]\n",
    "                ssname = sname[b].split(u'［')\n",
    "                \n",
    "                temp = ssname[0]\n",
    "                #print len(key) , key , len(temp.encode('utf8')) , temp.encode('utf8')\n",
    "                \n",
    "                #if key == ssname[0]:\n",
    "                if key == temp.encode('utf8'):\n",
    "                    check = 1\n",
    "                    if (u'画' in ssname[1] )or (u'著' in ssname[1] ):\n",
    "                        check = 2\n",
    "                        #print 'ok'\n",
    "                        \n",
    "                b = b + 1\n",
    "                #ssname[0] =  u'、' + ssname[0]\n",
    "                name = name + ssname[0] + u'、'\n",
    "                #print ssname[0]\n",
    "            #'''\n",
    "            \n",
    "            name = name.rstrip(u'、')\n",
    "            #print name\n",
    "            \n",
    "            #單作者檢查\n",
    "            '''\n",
    "            if soup.select('.list-name')[a].br:\n",
    "                #print '多作者處理'\n",
    "            '''            \n",
    "            \n",
    "            #書名\n",
    "            if (u'（成）' in cbook) and (check == 1):\n",
    "                check = 3\n",
    "                #print 'adult'\n",
    "            print cbook\n",
    "            \n",
    "            #日期\n",
    "            #print soup.select('.list-day')[a]\n",
    "            #print cdata\n",
    "            cdata = cdata.rstrip()\n",
    "            if len(cdata) < 8:\n",
    "                cdata = '0000/00/00'\n",
    "                print '/'\n",
    "            \n",
    "            if soup.select('.list-day')[a].br:\n",
    "                print '卷處理'\n",
    "            #print name.encode('utf8') , urllib.quote(key)\n",
    "            #print urllib.quote(name.encode('utf8'))\n",
    "            \n",
    "            #存檔處理\n",
    "            #if key == name.encode('utf8'):\n",
    "            if check > 1:\n",
    "                #print key ,  sname[0]\n",
    "                #print soup.select('.list-day')[a].text , soup.select('.list-name')[a].text\n",
    "                #fout.write(soup.select('.list-day')[a].text.encode('utf8') + cbook.encode('utf8')  + '\\n')\n",
    "                fout.write(cdata.encode('utf8') + cbook.encode('utf8')  + '\\n')\n",
    "            #print key ,  sname[0]\n",
    "            \n",
    "            \n",
    "            \n",
    "            #fout.write(soup.select('strong')[a].text.encode('utf8') + '\\n')\n",
    "            \n",
    "            a = a + 1\n",
    "            \n",
    "\n",
    "#資料筆數\n",
    "if soup.find_all('b')[1].text.isdigit():\n",
    "#if soup.find_all('b')[1].text > 0:\n",
    "    print key , soup.find_all('b')[1].text , '筆資料\\n========'\n",
    "    #print soup.find_all('b')\n",
    "    if soup.find_all('b')[1].text > 30:\n",
    "        print 'BIG'\n",
    "    fout = open(key.decode('utf8') + '_comiclist.txt', 'w')\n",
    "    fout.write('out\\n')\n",
    "    findbook()\n",
    "    fout.close()\n",
    "#print soup.select('.search_page_link_info')[1].text\n",
    "#print soup.select('.search_page_link_info')[1]\n",
    "\n",
    "#爬蟲重點內容\n",
    "#print soup.select('#listBOX-search')[0].text\n",
    "\n",
    "#print soup.select('td[class^=\"list-line\"]')\n",
    "#print res.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
